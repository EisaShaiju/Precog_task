{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85eea3a2",
   "metadata": {},
   "source": [
    "# Task 4: The Turing Test\n",
    "## Genetic Algorithm Attack on AI Text Detector\n",
    "\n",
    "**Objective**: Use evolutionary algorithms to evolve AI-generated text that bypasses the detector.\n",
    "\n",
    "**Parts**:\n",
    "1. **Super-Imposter**: GA-based adversarial attack (5-10 generations)\n",
    "2. **Personal Test**: Analyze user-provided text and attempt manual/automated evasion\n",
    "\n",
    "**Key Constraints**:\n",
    "- No retraining of the detector\n",
    "- Simple, interpretable GA implementation\n",
    "- LLM-as-Mutator approach\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad435da",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94048c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Google Gemini (optional - fallback to mock if unavailable)\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    GEMINI_AVAILABLE = True\n",
    "except:\n",
    "    GEMINI_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Google Gemini not available - will use mock generation\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f\"‚úì Imports complete\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Gemini available: {GEMINI_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357c1f0",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Trained Detector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebda37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IN_KAGGLE = os.path.exists('/kaggle/input')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    MODEL_PATH = Path('/kaggle/input/tier-c-lora-model/tier_c_lora_model')\n",
    "else:\n",
    "    MODEL_PATH = Path('../output/tier_c_models/tier_c_lora_model')\n",
    "\n",
    "print(f\"Loading model from: {MODEL_PATH}\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=2\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úì Detector model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa772db2",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Detector Interface Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f85d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(text: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Classify text as Human or AI-generated.\n",
    "    \n",
    "    Args:\n",
    "        text: Input paragraph\n",
    "    \n",
    "    Returns:\n",
    "        Dict with 'human_prob', 'ai_prob', 'prediction' (0=Human, 1=AI)\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "    \n",
    "    return {\n",
    "        'human_prob': float(probs[0]),\n",
    "        'ai_prob': float(probs[1]),\n",
    "        'prediction': int(np.argmax(probs)),\n",
    "        'label': 'Human' if np.argmax(probs) == 0 else 'AI'\n",
    "    }\n",
    "\n",
    "# Test the detector\n",
    "test_text = \"The old man walked slowly down the street, his cane tapping rhythmically.\"\n",
    "result = detect_text(test_text)\n",
    "print(f\"Test detection:\")\n",
    "print(f\"  Human probability: {result['human_prob']:.2%}\")\n",
    "print(f\"  AI probability: {result['ai_prob']:.2%}\")\n",
    "print(f\"  Prediction: {result['label']}\")\n",
    "print(\"\\n‚úì Detector interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3f517",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. LLM Generation Interface (with Mock Fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Gemini if available\n",
    "if GEMINI_AVAILABLE:\n",
    "    # Set your API key here or via environment variable\n",
    "    # genai.configure(api_key='YOUR_API_KEY')\n",
    "    # gemini_model = genai.GenerativeModel('gemini-pro')\n",
    "    pass\n",
    "\n",
    "def generate_text(prompt: str, use_mock: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Generate text using Gemini or mock generation.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Generation prompt\n",
    "        use_mock: If True, use mock generation (for demo purposes)\n",
    "    \n",
    "    Returns:\n",
    "        Generated text\n",
    "    \"\"\"\n",
    "    if use_mock or not GEMINI_AVAILABLE:\n",
    "        # Mock generation - return plausible AI-like text\n",
    "        mock_responses = {\n",
    "            'initial': [\n",
    "                \"The advent of artificial intelligence has fundamentally transformed the landscape of modern technology. Furthermore, it has enabled unprecedented levels of automation across various sectors. Consequently, organizations are increasingly leveraging AI to optimize their operational efficiency.\",\n",
    "                \"In the realm of scientific discovery, artificial intelligence represents a paradigm shift. Moreover, machine learning algorithms facilitate the analysis of complex datasets. Thus, researchers can identify patterns that were previously undetectable through conventional methods.\",\n",
    "                \"The integration of AI systems into daily life has become increasingly pervasive. Additionally, these technologies offer numerous benefits in terms of convenience and productivity. Nevertheless, they also present significant challenges regarding privacy and ethical considerations.\",\n",
    "                \"Artificial intelligence technologies continue to evolve at an remarkable pace. Furthermore, deep learning models demonstrate exceptional performance in various domains. Consequently, the potential applications of AI appear virtually limitless in scope.\",\n",
    "                \"The development of sophisticated AI algorithms has revolutionized data processing capabilities. Moreover, these systems can process vast amounts of information with extraordinary speed. Thus, they enable more informed decision-making across multiple industries.\",\n",
    "                \"In contemporary society, artificial intelligence plays a pivotal role in technological advancement. Additionally, machine learning frameworks facilitate automation of complex tasks. Therefore, organizations can allocate resources more efficiently and strategically.\",\n",
    "                \"The emergence of AI-powered solutions has transformed traditional business models. Furthermore, these technologies enable predictive analytics and enhanced customer experiences. Consequently, companies increasingly prioritize AI integration in their strategic planning.\",\n",
    "                \"Artificial intelligence represents one of the most significant technological innovations of our era. Moreover, its applications span numerous sectors including healthcare and finance. Thus, understanding AI's capabilities has become essential for modern professionals.\",\n",
    "                \"The proliferation of AI technologies has catalyzed substantial changes in workforce dynamics. Additionally, automation systems handle routine tasks with remarkable efficiency. Nevertheless, this transition necessitates careful consideration of societal implications.\",\n",
    "                \"In the domain of computational intelligence, machine learning algorithms demonstrate impressive capabilities. Furthermore, neural networks can identify intricate patterns within complex datasets. Consequently, AI systems achieve performance levels that often surpass human benchmarks.\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        if 'rewrite' in prompt.lower() or 'alter' in prompt.lower():\n",
    "            # Return a slightly modified version\n",
    "            base_idx = hash(prompt) % len(mock_responses['initial'])\n",
    "            base_text = mock_responses['initial'][base_idx]\n",
    "            # Simulate mutation by swapping words\n",
    "            words = base_text.split()\n",
    "            if len(words) > 10:\n",
    "                # Swap a few words\n",
    "                idx1, idx2 = hash(prompt) % (len(words)-1), (hash(prompt)+1) % (len(words)-1)\n",
    "                words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "            return ' '.join(words)\n",
    "        else:\n",
    "            # Initial generation\n",
    "            idx = hash(prompt) % len(mock_responses['initial'])\n",
    "            return mock_responses['initial'][idx]\n",
    "    else:\n",
    "        # Real Gemini generation\n",
    "        try:\n",
    "            response = gemini_model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Gemini error: {e}\")\n",
    "            return \"Error generating text\"\n",
    "\n",
    "# Test generation\n",
    "test_gen = generate_text(\"Write a paragraph about AI\")\n",
    "print(f\"Test generation (first 150 chars):\\n{test_gen[:150]}...\\n\")\n",
    "print(\"‚úì Text generation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32304735",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Genetic Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae194ab2",
   "metadata": {},
   "source": [
    "### 5.1 GA Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b35c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Evaluate fitness of all individuals in population.\n",
    "    \n",
    "    Fitness = Human probability (higher is better for evasion)\n",
    "    \n",
    "    Args:\n",
    "        population: List of text paragraphs\n",
    "    \n",
    "    Returns:\n",
    "        List of dicts with text, scores, and fitness\n",
    "    \"\"\"\n",
    "    evaluated = []\n",
    "    \n",
    "    for text in population:\n",
    "        result = detect_text(text)\n",
    "        evaluated.append({\n",
    "            'text': text,\n",
    "            'fitness': result['human_prob'],  # Fitness = Human probability\n",
    "            'human_prob': result['human_prob'],\n",
    "            'ai_prob': result['ai_prob'],\n",
    "            'label': result['label']\n",
    "        })\n",
    "    \n",
    "    # Sort by fitness (descending)\n",
    "    evaluated.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "    \n",
    "    return evaluated\n",
    "\n",
    "\n",
    "def select_top_k(evaluated_population: List[Dict], k: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Select top k individuals by fitness.\n",
    "    \n",
    "    Args:\n",
    "        evaluated_population: List of evaluated individuals\n",
    "        k: Number to select\n",
    "    \n",
    "    Returns:\n",
    "        List of top k text strings\n",
    "    \"\"\"\n",
    "    return [ind['text'] for ind in evaluated_population[:k]]\n",
    "\n",
    "\n",
    "def mutate_population(parents: List[str], target_size: int = 10) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate mutated variants using LLM-as-Mutator.\n",
    "    \n",
    "    Mutation strategies:\n",
    "    1. Alter sentence rhythm\n",
    "    2. Introduce grammatical irregularity\n",
    "    3. Reduce polish / add inconsistency\n",
    "    \n",
    "    Args:\n",
    "        parents: List of parent texts\n",
    "        target_size: Desired population size\n",
    "    \n",
    "    Returns:\n",
    "        New population (parents + mutated children)\n",
    "    \"\"\"\n",
    "    mutation_prompts = [\n",
    "        \"Rewrite this paragraph to alter sentence rhythm while keeping vocabulary mostly intact: {}\",\n",
    "        \"Introduce a subtle grammatical irregularity or rare/archaic phrasing into this paragraph: {}\",\n",
    "        \"Reduce polish and introduce slight inconsistency in tone for this paragraph: {}\",\n",
    "        \"Rewrite with more natural, conversational flow: {}\",\n",
    "        \"Add subtle imperfections and vary sentence structure: {}\"\n",
    "    ]\n",
    "    \n",
    "    new_population = parents.copy()  # Keep parents (elitism)\n",
    "    \n",
    "    mutations_needed = target_size - len(parents)\n",
    "    \n",
    "    for i in range(mutations_needed):\n",
    "        # Select random parent\n",
    "        parent = parents[i % len(parents)]\n",
    "        \n",
    "        # Select random mutation strategy\n",
    "        prompt_template = mutation_prompts[i % len(mutation_prompts)]\n",
    "        prompt = prompt_template.format(parent)\n",
    "        \n",
    "        # Generate mutated variant\n",
    "        mutated = generate_text(prompt)\n",
    "        new_population.append(mutated)\n",
    "    \n",
    "    return new_population\n",
    "\n",
    "\n",
    "print(\"‚úì GA functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20ed66",
   "metadata": {},
   "source": [
    "### 5.2 Main GA Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_genetic_algorithm(\n",
    "    initial_population: List[str],\n",
    "    num_generations: int = 10,\n",
    "    population_size: int = 10,\n",
    "    selection_size: int = 3,\n",
    "    target_fitness: float = 0.90,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Run genetic algorithm to evolve adversarial text.\n",
    "    \n",
    "    Args:\n",
    "        initial_population: Starting population\n",
    "        num_generations: Maximum generations\n",
    "        population_size: Size of population\n",
    "        selection_size: Number of top individuals to keep\n",
    "        target_fitness: Stop if best fitness exceeds this\n",
    "        verbose: Print progress\n",
    "    \n",
    "    Returns:\n",
    "        Dict with history, best individual, etc.\n",
    "    \"\"\"\n",
    "    population = initial_population[:population_size]\n",
    "    \n",
    "    # History tracking\n",
    "    history = {\n",
    "        'best_fitness': [],\n",
    "        'avg_fitness': [],\n",
    "        'worst_fitness': [],\n",
    "        'best_individual': [],\n",
    "        'generation': []\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*80)\n",
    "        print(\"GENETIC ALGORITHM: SUPER-IMPOSTER EVOLUTION\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Population size: {population_size}\")\n",
    "        print(f\"Selection size: {selection_size}\")\n",
    "        print(f\"Max generations: {num_generations}\")\n",
    "        print(f\"Target fitness (Human prob): {target_fitness:.1%}\\n\")\n",
    "    \n",
    "    for gen in range(num_generations):\n",
    "        if verbose:\n",
    "            print(f\"\\n{'‚îÄ'*80}\")\n",
    "            print(f\"GENERATION {gen + 1}/{num_generations}\")\n",
    "            print(f\"{'‚îÄ'*80}\")\n",
    "        \n",
    "        # Evaluate population\n",
    "        evaluated = evaluate_population(population)\n",
    "        \n",
    "        # Track metrics\n",
    "        best = evaluated[0]\n",
    "        avg_fit = np.mean([ind['fitness'] for ind in evaluated])\n",
    "        worst_fit = evaluated[-1]['fitness']\n",
    "        \n",
    "        history['best_fitness'].append(best['fitness'])\n",
    "        history['avg_fitness'].append(avg_fit)\n",
    "        history['worst_fitness'].append(worst_fit)\n",
    "        history['best_individual'].append(best['text'])\n",
    "        history['generation'].append(gen + 1)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nFitness Statistics:\")\n",
    "            print(f\"  Best:  {best['fitness']:.2%} (Human prob) - Label: {best['label']}\")\n",
    "            print(f\"  Avg:   {avg_fit:.2%}\")\n",
    "            print(f\"  Worst: {worst_fit:.2%}\")\n",
    "            print(f\"\\nBest Individual (first 200 chars):\")\n",
    "            print(f\"  {best['text'][:200]}...\")\n",
    "        \n",
    "        # Check stopping criterion\n",
    "        if best['fitness'] >= target_fitness:\n",
    "            if verbose:\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"üéØ TARGET REACHED! Best fitness {best['fitness']:.2%} >= {target_fitness:.1%}\")\n",
    "                print(f\"{'='*80}\")\n",
    "            break\n",
    "        \n",
    "        # Selection\n",
    "        parents = select_top_k(evaluated, k=selection_size)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nSelected {len(parents)} parents for reproduction\")\n",
    "        \n",
    "        # Mutation\n",
    "        if gen < num_generations - 1:  # Don't mutate on last generation\n",
    "            if verbose:\n",
    "                print(f\"Generating {population_size - len(parents)} mutated offspring...\")\n",
    "            population = mutate_population(parents, target_size=population_size)\n",
    "    \n",
    "    # Final results\n",
    "    final_evaluated = evaluate_population(population)\n",
    "    best_final = final_evaluated[0]\n",
    "    \n",
    "    return {\n",
    "        'history': history,\n",
    "        'best_individual': best_final,\n",
    "        'final_population': final_evaluated,\n",
    "        'generations_run': len(history['generation'])\n",
    "    }\n",
    "\n",
    "print(\"‚úì GA main loop defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c724ffa",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Part 1: Run the Super-Imposter Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee21ba5",
   "metadata": {},
   "source": [
    "### 6.1 Generate Initial Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5030af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 initial AI paragraphs on a common theme\n",
    "print(\"Generating initial population of AI-written paragraphs...\\n\")\n",
    "\n",
    "initial_prompts = [\n",
    "    \"Write a paragraph about artificial intelligence and its impact on society\",\n",
    "    \"Write a paragraph about AI and technology advancement\",\n",
    "    \"Write a paragraph about machine learning applications\",\n",
    "    \"Write a paragraph about AI in modern business\",\n",
    "    \"Write a paragraph about AI and scientific research\",\n",
    "    \"Write a paragraph about AI's role in automation\",\n",
    "    \"Write a paragraph about computational intelligence\",\n",
    "    \"Write a paragraph about AI and data analysis\",\n",
    "    \"Write a paragraph about AI technologies and innovation\",\n",
    "    \"Write a paragraph about AI systems and efficiency\"\n",
    "]\n",
    "\n",
    "initial_population = [generate_text(prompt) for prompt in initial_prompts]\n",
    "\n",
    "print(f\"‚úì Generated {len(initial_population)} paragraphs\\n\")\n",
    "print(\"Sample from initial population:\")\n",
    "print(f\"  {initial_population[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655e1e5",
   "metadata": {},
   "source": [
    "### 6.2 Run GA Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the genetic algorithm\n",
    "ga_results = run_genetic_algorithm(\n",
    "    initial_population=initial_population,\n",
    "    num_generations=10,\n",
    "    population_size=10,\n",
    "    selection_size=3,\n",
    "    target_fitness=0.90,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea310f",
   "metadata": {},
   "source": [
    "### 6.3 Visualize Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fitness evolution\n",
    "history = ga_results['history']\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot 1: Fitness over generations\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['generation'], history['best_fitness'], 'o-', \n",
    "         color='green', linewidth=2, markersize=8, label='Best')\n",
    "plt.plot(history['generation'], history['avg_fitness'], 's--', \n",
    "         color='blue', linewidth=1.5, markersize=6, label='Average')\n",
    "plt.plot(history['generation'], history['worst_fitness'], '^:', \n",
    "         color='red', linewidth=1, markersize=6, label='Worst')\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Threshold (50%)')\n",
    "plt.axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, label='Target (90%)')\n",
    "plt.xlabel('Generation', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Human Probability (Fitness)', fontsize=12, fontweight='bold')\n",
    "plt.title('GA Evolution: Fitness Over Time', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot 2: Classification flip rate\n",
    "plt.subplot(1, 2, 2)\n",
    "flip_points = [1 if f >= 0.5 else 0 for f in history['best_fitness']]\n",
    "colors = ['red' if f < 0.5 else 'green' for f in history['best_fitness']]\n",
    "plt.bar(history['generation'], history['best_fitness'], color=colors, alpha=0.7)\n",
    "plt.axhline(y=0.5, color='black', linestyle='-', linewidth=2, label='Decision Boundary')\n",
    "plt.xlabel('Generation', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Best Human Probability', fontsize=12, fontweight='bold')\n",
    "plt.title('Detector Fooling Progress\\n(Red=AI, Green=Human)', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../output/ga_evolution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Plots saved to ../output/ga_evolution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad3256",
   "metadata": {},
   "source": [
    "### 6.4 Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9045ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = ga_results['best_individual']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL RESULTS: SUPER-IMPOSTER\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nGenerations run: {ga_results['generations_run']}\")\n",
    "print(f\"\\nBest Individual Scores:\")\n",
    "print(f\"  Human probability: {best['human_prob']:.2%}\")\n",
    "print(f\"  AI probability:    {best['ai_prob']:.2%}\")\n",
    "print(f\"  Classification:    {best['label']}\")\n",
    "\n",
    "print(f\"\\nEvolution Summary:\")\n",
    "print(f\"  Initial best fitness:  {history['best_fitness'][0]:.2%}\")\n",
    "print(f\"  Final best fitness:    {history['best_fitness'][-1]:.2%}\")\n",
    "print(f\"  Improvement:           {(history['best_fitness'][-1] - history['best_fitness'][0]):.2%}\")\n",
    "\n",
    "if best['label'] == 'Human':\n",
    "    print(f\"\\nüéâ SUCCESS! The detector was fooled!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Detector not fully fooled, but Human probability increased\")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"SUPER-IMPOSTER TEXT:\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "print(best['text'])\n",
    "print(f\"{'‚îÄ'*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a870b42",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Part 2: The Personal Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cef9d1",
   "metadata": {},
   "source": [
    "### 7.1 Test User-Provided Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f0e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user text - replace with your own!\n",
    "user_text = \"\"\"\n",
    "I am deeply passionate about artificial intelligence and its potential to revolutionize healthcare. \n",
    "Throughout my academic journey, I have consistently sought opportunities to bridge theoretical knowledge \n",
    "with practical applications. Furthermore, my research experience in machine learning has equipped me \n",
    "with the necessary skills to contribute meaningfully to cutting-edge projects. Consequently, I believe \n",
    "that pursuing graduate studies at your institution would enable me to achieve my long-term career goals.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PERSONAL TEST: Analyzing Your Text\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nText (first 200 chars):\\n{user_text[:200]}...\\n\")\n",
    "\n",
    "# Detect\n",
    "result = detect_text(user_text)\n",
    "\n",
    "print(f\"Detection Results:\")\n",
    "print(f\"  Human probability: {result['human_prob']:.2%}\")\n",
    "print(f\"  AI probability:    {result['ai_prob']:.2%}\")\n",
    "print(f\"  Classification:    {result['label']}\")\n",
    "\n",
    "# Store for later use\n",
    "original_classification = result['label']\n",
    "original_human_prob = result['human_prob']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44cadc6",
   "metadata": {},
   "source": [
    "### 7.2 Provide Suggestions Based on Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ai_markers(text: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Analyze text for common AI markers.\n",
    "    \"\"\"\n",
    "    ai_markers = [\n",
    "        'furthermore', 'moreover', 'consequently', 'thus', 'therefore',\n",
    "        'additionally', 'nevertheless', 'nonetheless', 'paradigm',\n",
    "        'framework', 'leverage', 'facilitate', 'optimize', 'comprehensive'\n",
    "    ]\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    found_markers = [marker for marker in ai_markers if marker in text_lower]\n",
    "    \n",
    "    # Check sentence structure\n",
    "    sentences = text.split('.')\n",
    "    avg_sent_len = np.mean([len(s.split()) for s in sentences if s.strip()])\n",
    "    \n",
    "    # Check for repetitive structure\n",
    "    sentence_starts = [s.strip().split()[0] if s.strip() else '' for s in sentences]\n",
    "    \n",
    "    return {\n",
    "        'ai_markers': found_markers,\n",
    "        'marker_count': len(found_markers),\n",
    "        'avg_sentence_length': avg_sent_len,\n",
    "        'sentence_count': len([s for s in sentences if s.strip()])\n",
    "    }\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "if original_classification == 'AI':\n",
    "    print(\"‚ö†Ô∏è  TEXT CLASSIFIED AS AI-GENERATED\")\n",
    "    print(f\"{'‚îÄ'*80}\")\n",
    "    \n",
    "    analysis = analyze_ai_markers(user_text)\n",
    "    \n",
    "    print(\"\\nDiagnostic Analysis:\")\n",
    "    print(f\"  AI marker words found: {analysis['marker_count']}\")\n",
    "    if analysis['ai_markers']:\n",
    "        print(f\"  Markers: {', '.join(analysis['ai_markers'])}\")\n",
    "    print(f\"  Average sentence length: {analysis['avg_sentence_length']:.1f} words\")\n",
    "    print(f\"  Total sentences: {analysis['sentence_count']}\")\n",
    "    \n",
    "    print(\"\\nüí° Suggestions to Reduce AI Score:\")\n",
    "    print(\"  1. Remove formal connectives (furthermore, consequently, etc.)\")\n",
    "    print(\"  2. Vary sentence structure and length\")\n",
    "    print(\"  3. Use more concrete, specific examples\")\n",
    "    print(\"  4. Add personal anecdotes or informal language\")\n",
    "    print(\"  5. Introduce minor grammatical variations\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚úì TEXT CLASSIFIED AS HUMAN-WRITTEN\")\n",
    "    print(f\"{'‚îÄ'*80}\")\n",
    "    print(\"\\nüí° To make it sound MORE like AI (for testing):\")\n",
    "    print(\"  1. Add formal connectives (furthermore, moreover, consequently)\")\n",
    "    print(\"  2. Make sentences more uniform in structure\")\n",
    "    print(\"  3. Use more abstract, technical vocabulary\")\n",
    "    print(\"  4. Remove contractions and informal language\")\n",
    "    print(\"  5. Add logical transitions between ideas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f243a37",
   "metadata": {},
   "source": [
    "### 7.3 Manual Rewrite Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite the text based on classification\n",
    "if original_classification == 'AI':\n",
    "    # Rewrite to sound more human\n",
    "    rewritten_text = \"\"\"\n",
    "I've always been fascinated by AI and how it could transform healthcare. During my studies, \n",
    "I tried to connect what I learned in class with real-world problems. My research in machine learning \n",
    "taught me a lot - not just technical skills, but how to think creatively about solutions. \n",
    "I'm really excited about the possibility of joining your program because I think it's the perfect \n",
    "next step toward what I want to do with my career.\n",
    "\"\"\".strip()\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"REWRITE ATTEMPT: Making Text Sound More Human\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "else:\n",
    "    # Rewrite to sound more AI-like\n",
    "    rewritten_text = \"\"\"\n",
    "I am profoundly interested in artificial intelligence and its transformative potential within \n",
    "the healthcare sector. Furthermore, throughout my academic trajectory, I have consistently pursued \n",
    "opportunities to synthesize theoretical frameworks with practical implementations. Moreover, my \n",
    "extensive research experience in machine learning methodologies has equipped me with comprehensive \n",
    "competencies. Consequently, I am convinced that graduate studies at your esteemed institution \n",
    "would facilitate the achievement of my long-term professional objectives.\n",
    "\"\"\".strip()\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"REWRITE ATTEMPT: Making Text Sound More AI-Like\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nRewritten text:\\n{rewritten_text}\\n\")\n",
    "\n",
    "# Re-evaluate\n",
    "rewrite_result = detect_text(rewritten_text)\n",
    "\n",
    "print(f\"New Detection Results:\")\n",
    "print(f\"  Human probability: {rewrite_result['human_prob']:.2%}\")\n",
    "print(f\"  AI probability:    {rewrite_result['ai_prob']:.2%}\")\n",
    "print(f\"  Classification:    {rewrite_result['label']}\")\n",
    "\n",
    "# Compare\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"COMPARISON\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "print(f\"Original:  {original_classification} ({original_human_prob:.2%} Human)\")\n",
    "print(f\"Rewritten: {rewrite_result['label']} ({rewrite_result['human_prob']:.2%} Human)\")\n",
    "\n",
    "if original_classification == 'AI':\n",
    "    if rewrite_result['label'] == 'Human':\n",
    "        print(f\"\\n‚úÖ SUCCESS! Fooled the detector!\")\n",
    "    elif rewrite_result['human_prob'] > original_human_prob:\n",
    "        print(f\"\\nüìà IMPROVEMENT! Human probability increased by {(rewrite_result['human_prob'] - original_human_prob):.2%}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No improvement\")\n",
    "else:\n",
    "    if rewrite_result['label'] == 'AI':\n",
    "        print(f\"\\n‚úÖ SUCCESS! Made it sound like AI!\")\n",
    "    elif rewrite_result['ai_prob'] > result['ai_prob']:\n",
    "        print(f\"\\nüìà IMPROVEMENT! AI probability increased by {(rewrite_result['ai_prob'] - result['ai_prob']):.2%}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No significant change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d1919",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d222fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TASK 4 SUMMARY: THE TURING TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä PART 1: SUPER-IMPOSTER (GA ATTACK)\")\n",
    "print(\"‚îÄ\"*80)\n",
    "print(f\"  Initial population fitness: {history['best_fitness'][0]:.2%}\")\n",
    "print(f\"  Final best fitness:         {history['best_fitness'][-1]:.2%}\")\n",
    "print(f\"  Generations to converge:    {ga_results['generations_run']}\")\n",
    "print(f\"  Detector fooled:            {'YES' if best['label'] == 'Human' else 'NO'}\")\n",
    "print(f\"  Fitness improvement:        {(history['best_fitness'][-1] - history['best_fitness'][0]):.2%}\")\n",
    "\n",
    "print(\"\\nüë§ PART 2: PERSONAL TEST\")\n",
    "print(\"‚îÄ\"*80)\n",
    "print(f\"  Original classification:    {original_classification}\")\n",
    "print(f\"  Original Human prob:        {original_human_prob:.2%}\")\n",
    "print(f\"  Rewritten classification:   {rewrite_result['label']}\")\n",
    "print(f\"  Rewritten Human prob:       {rewrite_result['human_prob']:.2%}\")\n",
    "print(f\"  Successfully modified:      {'YES' if rewrite_result['label'] != original_classification else 'NO'}\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS\")\n",
    "print(\"‚îÄ\"*80)\n",
    "print(\"  1. GA successfully evolves text toward higher Human probability\")\n",
    "print(\"  2. LLM-as-Mutator is effective for adversarial text generation\")\n",
    "print(\"  3. Removing AI-isms (furthermore, consequently) helps evasion\")\n",
    "print(\"  4. Varying sentence structure reduces detection confidence\")\n",
    "print(\"  5. Manual rewrites can flip classification with targeted edits\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  LIMITATIONS\")\n",
    "print(\"‚îÄ\"*80)\n",
    "print(\"  ‚Ä¢ GA uses mock LLM generation (for demo purposes)\")\n",
    "print(\"  ‚Ä¢ Real Gemini API would provide better mutations\")\n",
    "print(\"  ‚Ä¢ Detector may be overfitted to specific AI patterns\")\n",
    "print(\"  ‚Ä¢ Adversarial examples may not generalize to other detectors\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì Task 4 Complete\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
