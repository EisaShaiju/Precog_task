{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14756256,"sourceType":"datasetVersion","datasetId":9431569}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"85eea3a2","cell_type":"markdown","source":"# Task 4: The Turing Test\n## Genetic Algorithm Attack on AI Text Detector\n\n**Objective**: Use evolutionary algorithms to evolve AI-generated text that bypasses the detector.\n\n**Parts**:\n1. **Super-Imposter**: GA-based adversarial attack (5-10 generations)\n2. **Personal Test**: Analyze user-provided text and attempt manual/automated evasion\n\n**Key Constraints**:\n- No retraining of the detector\n- Simple, interpretable GA implementation\n- LLM-as-Mutator approach\n\n---","metadata":{}},{"id":"6ad435da","cell_type":"markdown","source":"## 1. Setup & Imports","metadata":{}},{"id":"94048c42","cell_type":"code","source":"# Core imports\nimport json\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom typing import List, Tuple, Dict\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Transformers\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# Google Gemini (optional - fallback to mock if unavailable)\ntry:\n    import google.generativeai as genai\n    GEMINI_AVAILABLE = True\nexcept:\n    GEMINI_AVAILABLE = False\n    print(\"  Google Gemini needs to be set\")\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nMAX_LENGTH = 256\n\n# Plotting style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(f\"‚úì Imports complete\")\nprint(f\"Device: {device}\")\nprint(f\"Gemini available: {GEMINI_AVAILABLE}\")","metadata":{"execution":{"iopub.status.busy":"2026-02-07T06:16:53.707236Z","iopub.execute_input":"2026-02-07T06:16:53.707693Z","iopub.status.idle":"2026-02-07T06:17:11.925472Z","shell.execute_reply.started":"2026-02-07T06:16:53.707661Z","shell.execute_reply":"2026-02-07T06:17:11.924468Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úì Imports complete\nDevice: cpu\nGemini available: True\n","output_type":"stream"}],"execution_count":1},{"id":"6357c1f0","cell_type":"markdown","source":"---\n## 2. Load Trained Detector Model","metadata":{}},{"id":"9ebda37d","cell_type":"code","source":"import os\n\nIN_KAGGLE = os.path.exists('/kaggle/input')\n\nif IN_KAGGLE:\n    MODEL_PATH = Path('/kaggle/input/tier-c-lora-model/tier_c_lora_model')\nelse:\n    MODEL_PATH = Path('../output/tier_c_models/tier_c_lora_model')\n\nprint(f\"Loading model from: {MODEL_PATH}\")\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_PATH,\n    num_labels=2\n)\nmodel.to(device)\nmodel.eval()\n\nprint(\"‚úì Detector model loaded successfully!\")","metadata":{"execution":{"iopub.status.busy":"2026-02-07T06:17:14.449667Z","iopub.execute_input":"2026-02-07T06:17:14.450739Z","iopub.status.idle":"2026-02-07T06:17:40.086844Z","shell.execute_reply.started":"2026-02-07T06:17:14.450699Z","shell.execute_reply":"2026-02-07T06:17:40.085882Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Loading model from: /kaggle/input/tier-c-lora-model/tier_c_lora_model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b3ff9b5af514ca6b6384d3561b528c9"}},"metadata":{}},{"name":"stderr","text":"2026-02-07 06:17:18.383597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770445038.657936      99 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770445038.730983      99 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770445039.373586      99 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770445039.373645      99 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770445039.373648      99 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770445039.373651      99 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca23e454c11a4933a4d6fb4e185ffa99"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"‚úì Detector model loaded successfully!\n","output_type":"stream"}],"execution_count":2},{"id":"aa772db2","cell_type":"markdown","source":"---\n## 3. Detector Interface Function","metadata":{}},{"id":"c6f85d4d","cell_type":"code","source":"def detect_text(text: str) -> Dict[str, float]:\n    \"\"\"\n    Classify text as Human or AI-generated.\n    \n    Args:\n        text: Input paragraph\n    \n    Returns:\n        Dict with 'human_prob', 'ai_prob', 'prediction' (0=Human, 1=AI)\n    \"\"\"\n    inputs = tokenizer(\n        text,\n        return_tensors='pt',\n        truncation=True,\n        max_length=MAX_LENGTH,\n        padding='max_length'\n    )\n    \n    input_ids = inputs['input_ids'].to(device)\n    attention_mask = inputs['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n    \n    return {\n        'human_prob': float(probs[0]),\n        'ai_prob': float(probs[1]),\n        'prediction': int(np.argmax(probs)),\n        'label': 'Human' if np.argmax(probs) == 0 else 'AI'\n    }\n\n# Test the detector\ntest_text = \"The old man walked slowly down the street, his cane tapping rhythmically.\"\nresult = detect_text(test_text)\nprint(f\"Test detection:\")\nprint(f\"  Human probability: {result['human_prob']:.2%}\")\nprint(f\"  AI probability: {result['ai_prob']:.2%}\")\nprint(f\"  Prediction: {result['label']}\")\nprint(\"\\n‚úì Detector interface ready\")","metadata":{"execution":{"iopub.status.busy":"2026-02-07T06:17:44.714567Z","iopub.execute_input":"2026-02-07T06:17:44.715963Z","iopub.status.idle":"2026-02-07T06:17:45.200586Z","shell.execute_reply.started":"2026-02-07T06:17:44.715925Z","shell.execute_reply":"2026-02-07T06:17:45.199491Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Test detection:\n  Human probability: 99.75%\n  AI probability: 0.25%\n  Prediction: Human\n\n‚úì Detector interface ready\n","output_type":"stream"}],"execution_count":3},{"id":"52e3f517","cell_type":"markdown","source":"---\n## 4. LLM Generation Interface (with Mock Fallback)","metadata":{}},{"id":"9ef7ec67","cell_type":"code","source":"import os\nimport google.generativeai as genai\nfrom kaggle_secrets import UserSecretsClient\n\n# Read API key from Kaggle Secrets - THE CORRECT WAY\nuser_secrets = UserSecretsClient()\ntry:\n    GEMINI_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\n    GEMINI_AVAILABLE = True\nexcept:\n    GEMINI_API_KEY = None\n    GEMINI_AVAILABLE = False\n\nif GEMINI_AVAILABLE:\n    genai.configure(api_key=GEMINI_API_KEY)\n    gemini_model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n    print(\"‚úì Gemini API detected and configured\")\nelse:\n    gemini_model = None\n    print(\"‚ö† Gemini API key not found - using mock generation\")","metadata":{"execution":{"iopub.status.busy":"2026-02-07T06:22:52.482112Z","iopub.execute_input":"2026-02-07T06:22:52.482665Z","iopub.status.idle":"2026-02-07T06:22:52.725704Z","shell.execute_reply.started":"2026-02-07T06:22:52.482631Z","shell.execute_reply":"2026-02-07T06:22:52.724622Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úì Gemini API detected and configured\n","output_type":"stream"}],"execution_count":11},{"id":"b45a7234","cell_type":"code","source":"def generate_text(prompt: str, use_mock: bool = False) -> str:\n    \"\"\"\n    Generate text using Gemini or mock generation.\n    \n    Args:\n        prompt: Generation prompt\n        use_mock: If True, use mock generation (for demo purposes)\n    \n    Returns:\n        Generated text\n    \"\"\"\n      \n    # if 'rewrite' in prompt.lower() or 'alter' in prompt.lower():\n    #     # Return a slightly modified version\n    #     base_idx = hash(prompt) % len(mock_responses['initial'])\n    #     base_text = mock_responses['initial'][base_idx]\n    #     # Simulate mutation by swapping words\n    #     words = base_text.split()\n    #     if len(words) > 10:\n    #         # Swap a few words\n    #         idx1, idx2 = hash(prompt) % (len(words)-1), (hash(prompt)+1) % (len(words)-1)\n    #         words[idx1], words[idx2] = words[idx2], words[idx1]\n    #     return ' '.join(words)\n    # else:\n    #     # Initial generation\n    #     idx = hash(prompt) % len(mock_responses['initial'])\n    #     return mock_responses['initial'][idx]\n    # else:\n    #     # Real Gemini generation\n    try:\n        response = gemini_model.generate_content(prompt)\n        return response.text\n    except Exception as e:\n        print(f\"Gemini error: {e}\")\n        return \"Error generating text\"\n\n# Test generation\ntest_gen = generate_text(\"Write a paragraph about AI\")\nprint(f\"Test generation (first 150 chars):\\n{test_gen[:150]}...\\n\")\nprint(\"‚úì Text generation ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T06:17:50.778438Z","iopub.execute_input":"2026-02-07T06:17:50.778889Z","iopub.status.idle":"2026-02-07T06:17:56.909209Z","shell.execute_reply.started":"2026-02-07T06:17:50.778848Z","shell.execute_reply":"2026-02-07T06:17:56.908094Z"}},"outputs":[{"name":"stdout","text":"Test generation (first 150 chars):\nArtificial Intelligence (AI) represents one of the most transformative technological advancements of the modern era, fundamentally reshaping how we in...\n\n‚úì Text generation ready\n","output_type":"stream"}],"execution_count":5},{"id":"32304735","cell_type":"markdown","source":"---\n## 5. Genetic Algorithm Implementation","metadata":{}},{"id":"ae194ab2","cell_type":"markdown","source":"### 5.1 GA Helper Functions","metadata":{}},{"id":"f3b35c53","cell_type":"code","source":"def evaluate_population(population: List[str]) -> List[Dict]:\n    \"\"\"\n    Evaluate fitness of all individuals in population.\n    \n    Fitness = Human probability (higher is better for evasion)\n    \n    Args:\n        population: List of text paragraphs\n    \n    Returns:\n        List of dicts with text, scores, and fitness\n    \"\"\"\n    evaluated = []\n    \n    for text in population:\n        result = detect_text(text)\n        evaluated.append({\n            'text': text,\n            'fitness': result['human_prob'],  # Fitness = Human probability\n            'human_prob': result['human_prob'],\n            'ai_prob': result['ai_prob'],\n            'label': result['label']\n        })\n    \n    # Sort by fitness (descending)\n    evaluated.sort(key=lambda x: x['fitness'], reverse=True)\n    \n    return evaluated\n\n\ndef select_top_k(evaluated_population: List[Dict], k: int = 3) -> List[str]:\n    \"\"\"\n    Select top k individuals by fitness.\n    \n    Args:\n        evaluated_population: List of evaluated individuals\n        k: Number to select\n    \n    Returns:\n        List of top k text strings\n    \"\"\"\n    return [ind['text'] for ind in evaluated_population[:k]]\n\n\ndef mutate_population(parents: List[str], target_size: int = 10) -> List[str]:\n    \"\"\"\n    Generate mutated variants using LLM-as-Mutator.\n    \n    Mutation strategies:\n    1. Alter sentence rhythm\n    2. Introduce grammatical irregularity\n    3. Reduce polish / add inconsistency\n    \n    Args:\n        parents: List of parent texts\n        target_size: Desired population size\n    \n    Returns:\n        New population (parents + mutated children)\n    \"\"\"\n    mutation_prompts = [\n        \"Rewrite this paragraph to alter sentence rhythm while keeping vocabulary mostly intact: {}\",\n        \"Introduce a subtle grammatical irregularity or rare/archaic phrasing into this paragraph: {}\",\n        \"Reduce polish and introduce slight inconsistency in tone for this paragraph: {}\",\n        \"Rewrite with more natural, conversational flow: {}\",\n        \"Add subtle imperfections and vary sentence structure: {}\"\n    ]\n    \n    new_population = parents.copy()  # Keep parents (elitism)\n    \n    mutations_needed = target_size - len(parents)\n    \n    for i in range(mutations_needed):\n        # Select random parent\n        parent = parents[i % len(parents)]\n        \n        # Select random mutation strategy\n        prompt_template = mutation_prompts[i % len(mutation_prompts)]\n        prompt = prompt_template.format(parent)\n        \n        # Generate mutated variant\n        mutated = generate_text(prompt)\n        new_population.append(mutated)\n    \n    return new_population\n\n\nprint(\" GA functions defined\")","metadata":{"execution":{"iopub.status.busy":"2026-02-07T06:18:03.207593Z","iopub.execute_input":"2026-02-07T06:18:03.208784Z","iopub.status.idle":"2026-02-07T06:18:03.219020Z","shell.execute_reply.started":"2026-02-07T06:18:03.208747Z","shell.execute_reply":"2026-02-07T06:18:03.217856Z"},"trusted":true},"outputs":[{"name":"stdout","text":" GA functions defined\n","output_type":"stream"}],"execution_count":6},{"id":"9b20ed66","cell_type":"markdown","source":"### 5.2 Main GA Loop","metadata":{}},{"id":"0aaa5f51","cell_type":"code","source":"def run_genetic_algorithm_with_checkpointing(\n    initial_population: List[str],\n    num_generations: int = 10,\n    population_size: int = 10,\n    selection_size: int = 3,\n    target_fitness: float = 0.90,\n    verbose: bool = True,\n    checkpoint_file: str = 'ga_checkpoint.pkl',\n    resume_from_checkpoint: bool = False\n) -> Dict:\n    \"\"\"\n    Run genetic algorithm with automatic checkpointing.\n    Can resume from checkpoint after rate limit errors.\n    \n    Args:\n        initial_population: Starting population\n        num_generations: Maximum generations\n        population_size: Size of population\n        selection_size: Number of top individuals to keep\n        target_fitness: Stop if best fitness exceeds this\n        verbose: Print progress\n        checkpoint_file: Where to save progress\n        resume_from_checkpoint: If True, load from checkpoint\n    \n    Returns:\n        Dict with history, best individual, etc.\n    \"\"\"\n    \n    # Try to resume from checkpoint\n    if resume_from_checkpoint:\n        try:\n            with open(checkpoint_file, 'rb') as f:\n                checkpoint = pickle.load(f)\n            \n            population = checkpoint['population']\n            history = checkpoint['history']\n            start_gen = checkpoint['last_generation'] + 1\n            \n            if verbose:\n                print(f\"üìÇ RESUMING FROM CHECKPOINT\")\n                print(f\"   Last completed generation: {checkpoint['last_generation']}\")\n                print(f\"   Continuing from generation: {start_gen}\")\n                print(f\"   Population size: {len(population)}\\n\")\n        except FileNotFoundError:\n            if verbose:\n                print(f\"‚ö†Ô∏è  No checkpoint found. Starting fresh.\\n\")\n            resume_from_checkpoint = False\n    \n    # Initialize fresh if not resuming\n    if not resume_from_checkpoint:\n        population = initial_population[:population_size]\n        history = {\n            'best_fitness': [],\n            'avg_fitness': [],\n            'worst_fitness': [],\n            'best_individual': [],\n            'generation': []\n        }\n        start_gen = 0\n    \n    if verbose and start_gen == 0:\n        print(\"=\"*80)\n        print(\"GENETIC ALGORITHM: SUPER-IMPOSTER EVOLUTION\")\n        print(\"=\"*80)\n        print(f\"Population size: {population_size}\")\n        print(f\"Selection size: {selection_size}\")\n        print(f\"Max generations: {num_generations}\")\n        print(f\"Target fitness (Human prob): {target_fitness:.1%}\\n\")\n    \n    # Main GA loop\n    for gen in range(start_gen, num_generations):\n        if verbose:\n            print(f\"\\n{'‚îÄ'*80}\")\n            print(f\"GENERATION {gen + 1}/{num_generations}\")\n            print(f\"{'‚îÄ'*80}\")\n        \n        try:\n            # Evaluate population\n            evaluated = evaluate_population(population)\n            \n            # Track metrics\n            best = evaluated[0]\n            avg_fit = np.mean([ind['fitness'] for ind in evaluated])\n            worst_fit = evaluated[-1]['fitness']\n            \n            history['best_fitness'].append(best['fitness'])\n            history['avg_fitness'].append(avg_fit)\n            history['worst_fitness'].append(worst_fit)\n            history['best_individual'].append(best['text'])\n            history['generation'].append(gen + 1)\n            \n            if verbose:\n                print(f\"\\nFitness Statistics:\")\n                print(f\"  Best:  {best['fitness']:.2%} (Human prob) - Label: {best['label']}\")\n                print(f\"  Avg:   {avg_fit:.2%}\")\n                print(f\"  Worst: {worst_fit:.2%}\")\n                print(f\"\\nBest Individual (first 200 chars):\")\n                print(f\"  {best['text'][:200]}...\")\n            \n            # Save checkpoint after successful generation\n            checkpoint = {\n                'population': evaluated,  # Save evaluated population with fitness scores\n                'history': history,\n                'last_generation': gen,\n                'timestamp': datetime.now().isoformat()\n            }\n            \n            with open(checkpoint_file, 'wb') as f:\n                pickle.dump(checkpoint, f)\n            \n            if verbose:\n                print(f\"\\nüíæ Checkpoint saved (generation {gen + 1})\")\n            \n            # Check stopping criterion\n            if best['fitness'] >= target_fitness:\n                if verbose:\n                    print(f\"\\n{'='*80}\")\n                    print(f\"üéØ TARGET REACHED! Best fitness {best['fitness']:.2%} >= {target_fitness:.1%}\")\n                    print(f\"{'='*80}\")\n                break\n            \n            # Selection\n            parents = select_top_k(evaluated, k=selection_size)\n            \n            if verbose:\n                print(f\"\\nSelected {len(parents)} parents for reproduction\")\n            \n            # Mutation for next generation\n            if gen < num_generations - 1:\n                if verbose:\n                    print(f\"Generating {population_size - len(parents)} mutated offspring...\")\n                \n                # Extract just the text from evaluated parents\n                parent_texts = [p['text'] for p in parents]\n                population = mutate_population(parent_texts, target_size=population_size)\n        \n        except Exception as e:\n            # If rate limit hit, save checkpoint and exit gracefully\n            if \"429\" in str(e) or \"quota\" in str(e).lower():\n                print(f\"\\n‚ö†Ô∏è  RATE LIMIT HIT at generation {gen + 1}\")\n                print(f\"üíæ Progress saved to {checkpoint_file}\")\n                print(f\"\\nüîÑ To resume, run:\")\n                print(f\"   results = run_genetic_algorithm_with_checkpointing(\")\n                print(f\"       initial_population,\")\n                print(f\"       resume_from_checkpoint=True\")\n                print(f\"   )\")\n                \n                # Save what we have so far\n                checkpoint = {\n                    'population': population,\n                    'history': history,\n                    'last_generation': gen - 1,  # Last completed generation\n                    'timestamp': datetime.now().isoformat(),\n                    'error': str(e)\n                }\n                \n                with open(checkpoint_file, 'wb') as f:\n                    pickle.dump(checkpoint, f)\n                \n                return {\n                    'history': history,\n                    'checkpoint_saved': True,\n                    'last_generation': gen - 1,\n                    'resume_available': True\n                }\n            else:\n                # Some other error\n                raise e\n    \n    # Final results\n    final_evaluated = evaluate_population(population)\n    best_final = final_evaluated[0]\n    \n    return {\n        'history': history,\n        'best_individual': best_final,\n        'final_population': final_evaluated,\n        'generations_run': len(history['generation']),\n        'completed': True\n    }\n\n\n# ============================================================================\n# STEP 2: Helper Function to Check Checkpoint Status\n# ============================================================================\n\ndef check_checkpoint_status(checkpoint_file='ga_checkpoint.pkl'):\n    \"\"\"Check what's in the checkpoint file\"\"\"\n    try:\n        with open(checkpoint_file, 'rb') as f:\n            checkpoint = pickle.load(f)\n        \n        print(\"=\"*80)\n        print(\"CHECKPOINT STATUS\")\n        print(\"=\"*80)\n        print(f\"Last completed generation: {checkpoint['last_generation']}\")\n        print(f\"Population size: {len(checkpoint['population'])}\")\n        print(f\"Saved at: {checkpoint['timestamp']}\")\n        \n        if 'history' in checkpoint:\n            history = checkpoint['history']\n            if history['best_fitness']:\n                print(f\"\\nBest fitness so far: {max(history['best_fitness']):.2%}\")\n                print(f\"Generations completed: {len(history['generation'])}\")\n        \n        if 'error' in checkpoint:\n            print(f\"\\nStopped due to: {checkpoint['error'][:100]}...\")\n        \n        print(\"\\n‚úÖ Ready to resume!\")\n        print(\"=\"*80)\n        \n        return True\n    except FileNotFoundError:\n        print(\"‚ùå No checkpoint found.\")\n        return False","metadata":{"execution":{"iopub.status.busy":"2026-02-07T06:24:58.557630Z","iopub.execute_input":"2026-02-07T06:24:58.557979Z","iopub.status.idle":"2026-02-07T06:24:58.582937Z","shell.execute_reply.started":"2026-02-07T06:24:58.557950Z","shell.execute_reply":"2026-02-07T06:24:58.581841Z"},"trusted":true},"outputs":[],"execution_count":15},{"id":"7c724ffa","cell_type":"markdown","source":"---\n## 6. Part 1: Run the Super-Imposter Attack","metadata":{}},{"id":"7ee21ba5","cell_type":"markdown","source":"### 6.1 Generate Initial Population","metadata":{}},{"id":"b5030af2","cell_type":"code","source":"# Generate 10 initial AI paragraphs on a common theme\nprint(\"Generating initial population of AI-written paragraphs...\\n\")\n\ninitial_prompts = [\n    \"Write a paragraph about artificial intelligence and its impact on society\",\n    \"Write a paragraph about AI and technology advancement\",\n    \"Write a paragraph about machine learning applications\",\n    \"Write a paragraph about AI in modern business\",\n    \"Write a paragraph about AI and scientific research\",\n    \"Write a paragraph about AI's role in automation\",\n    \"Write a paragraph about computational intelligence\",\n    \"Write a paragraph about AI and data analysis\",\n    \"Write a paragraph about AI technologies and innovation\",\n    \"Write a paragraph about AI systems and efficiency\"\n]\n\ninitial_population = [generate_text(prompt) for prompt in initial_prompts]\n\nprint(f\" Generated {len(initial_population)} paragraphs\\n\")\nprint(\"Sample from initial population:\")\nprint(f\"  {initial_population[0][:200]}...\")","metadata":{"execution":{"iopub.status.busy":"2026-02-07T06:23:04.112234Z","iopub.execute_input":"2026-02-07T06:23:04.113096Z","iopub.status.idle":"2026-02-07T06:23:29.982654Z","shell.execute_reply.started":"2026-02-07T06:23:04.113059Z","shell.execute_reply":"2026-02-07T06:23:29.981595Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Generating initial population of AI-written paragraphs...\n\n Generated 10 paragraphs\n\nSample from initial population:\n  Artificial intelligence (AI) is rapidly transforming our world, offering profound implications for nearly every aspect of society. From automating complex tasks and personalizing our experiences to dr...\n","output_type":"stream"}],"execution_count":12},{"id":"0655e1e5","cell_type":"markdown","source":"### 6.2 Run GA Evolution","metadata":{}},{"id":"9d7b45ff","cell_type":"code","source":"import pickle\nimport json\nfrom datetime import datetime\n# Run the genetic algorithm\nga_results = run_genetic_algorithm_with_checkpointing(\n    initial_population,\n    num_generations=10,\n    population_size=10,\n    resume_from_checkpoint=False  # Start fresh\n)","metadata":{"execution":{"iopub.status.busy":"2026-02-07T06:25:36.464034Z","iopub.execute_input":"2026-02-07T06:25:36.464987Z","iopub.status.idle":"2026-02-07T06:25:39.064514Z","shell.execute_reply.started":"2026-02-07T06:25:36.464930Z","shell.execute_reply":"2026-02-07T06:25:39.063201Z"},"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nGENETIC ALGORITHM: SUPER-IMPOSTER EVOLUTION\n================================================================================\nPopulation size: 10\nSelection size: 3\nMax generations: 10\nTarget fitness (Human prob): 90.0%\n\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nGENERATION 1/10\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nFitness Statistics:\n  Best:  0.03% (Human prob) - Label: AI\n  Avg:   0.01%\n  Worst: 0.00%\n\nBest Individual (first 200 chars):\n  Computational intelligence (CI) is a subfield of artificial intelligence that focuses on developing systems capable of learning, adapting, and solving problems in ways inspired by nature. Unlike tradi...\n\nüíæ Checkpoint saved (generation 1)\n\nSelected 3 parents for reproduction\nGenerating 7 mutated offspring...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_99/152380931.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run the genetic algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m ga_results = run_genetic_algorithm_with_checkpointing(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0minitial_population\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnum_generations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_99/4113092163.py\u001b[0m in \u001b[0;36mrun_genetic_algorithm_with_checkpointing\u001b[0;34m(initial_population, num_generations, population_size, selection_size, target_fitness, verbose, checkpoint_file, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m# Some other error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m# Final results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_99/4113092163.py\u001b[0m in \u001b[0;36mrun_genetic_algorithm_with_checkpointing\u001b[0;34m(initial_population, num_generations, population_size, selection_size, target_fitness, verbose, checkpoint_file, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# Extract just the text from evaluated parents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mparent_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutate_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"],"ename":"TypeError","evalue":"string indices must be integers, not 'str'","output_type":"error"}],"execution_count":17},{"id":"f1f21a79-f106-49c7-8be8-c279b224cf90","cell_type":"code","source":"check_checkpoint_status()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bd8844a4-a0a6-47c6-b859-6e550d909c0d","cell_type":"code","source":"ga_results = run_genetic_algorithm_with_checkpointing(\n    initial_population,  # Same as before (won't be used, just needed as parameter)\n    num_generations=10,\n    population_size=10,\n    resume_from_checkpoint=True  # ‚Üê This is the key!\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7fea310f","cell_type":"markdown","source":"### 6.3 Visualize Evolution","metadata":{}},{"id":"c8f6ed84","cell_type":"code","source":"# Plot fitness evolution\nhistory = ga_results['history']\n\n# Create output directory if it doesn't exist\nPath('../output').mkdir(parents=True, exist_ok=True)\n\nplt.figure(figsize=(14, 6))\n\n# Plot 1: Fitness over generations\nplt.subplot(1, 2, 1)\nplt.plot(history['generation'], history['best_fitness'], 'o-', \n         color='green', linewidth=2, markersize=8, label='Best')\nplt.plot(history['generation'], history['avg_fitness'], 's--', \n         color='blue', linewidth=1.5, markersize=6, label='Average')\nplt.plot(history['generation'], history['worst_fitness'], '^:', \n         color='red', linewidth=1, markersize=6, label='Worst')\nplt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Threshold (50%)')\nplt.axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, label='Target (90%)')\nplt.xlabel('Generation', fontsize=12, fontweight='bold')\nplt.ylabel('Human Probability (Fitness)', fontsize=12, fontweight='bold')\nplt.title('GA Evolution: Fitness Over Time', fontsize=14, fontweight='bold')\nplt.legend(loc='best')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\n\n# Plot 2: Classification flip rate\nplt.subplot(1, 2, 2)\nflip_points = [1 if f >= 0.5 else 0 for f in history['best_fitness']]\ncolors = ['red' if f < 0.5 else 'green' for f in history['best_fitness']]\nplt.bar(history['generation'], history['best_fitness'], color=colors, alpha=0.7)\nplt.axhline(y=0.5, color='black', linestyle='-', linewidth=2, label='Decision Boundary')\nplt.xlabel('Generation', fontsize=12, fontweight='bold')\nplt.ylabel('Best Human Probability', fontsize=12, fontweight='bold')\nplt.title('Detector Fooling Progress\\n(Red=AI, Green=Human)', fontsize=14, fontweight='bold')\nplt.legend()\nplt.grid(True, alpha=0.3, axis='y')\nplt.tight_layout()\n\nplt.savefig('../output/ga_evolution.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\n‚úì Plots saved to ../output/ga_evolution.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"56ad3256","cell_type":"markdown","source":"### 6.4 Final Results","metadata":{}},{"id":"f9045ee9","cell_type":"code","source":"best = ga_results['best_individual']\n\nprint(\"=\"*80)\nprint(\"FINAL RESULTS: SUPER-IMPOSTER\")\nprint(\"=\"*80)\nprint(f\"\\nGenerations run: {ga_results['generations_run']}\")\nprint(f\"\\nBest Individual Scores:\")\nprint(f\"  Human probability: {best['human_prob']:.2%}\")\nprint(f\"  AI probability:    {best['ai_prob']:.2%}\")\nprint(f\"  Classification:    {best['label']}\")\n\nprint(f\"\\nEvolution Summary:\")\nprint(f\"  Initial best fitness:  {history['best_fitness'][0]:.2%}\")\nprint(f\"  Final best fitness:    {history['best_fitness'][-1]:.2%}\")\nprint(f\"  Improvement:           {(history['best_fitness'][-1] - history['best_fitness'][0]):.2%}\")\n\nif best['label'] == 'Human':\n    print(f\"\\nüéâ SUCCESS! The detector was fooled!\")\nelse:\n    print(f\"\\n‚ö†Ô∏è  Detector not fully fooled, but Human probability increased\")\n\nprint(f\"\\n{'‚îÄ'*80}\")\nprint(\"SUPER-IMPOSTER TEXT:\")\nprint(f\"{'‚îÄ'*80}\")\nprint(best['text'])\nprint(f\"{'‚îÄ'*80}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8a870b42","cell_type":"markdown","source":"---\n## 7. Part 2: The Personal Test","metadata":{}},{"id":"e7cef9d1","cell_type":"markdown","source":"### 7.1 Test User-Provided Text","metadata":{}},{"id":"6c7f0e10","cell_type":"code","source":"# Example user text - replace with your own!\nuser_text = \"\"\"\nI am deeply passionate about artificial intelligence and its potential to revolutionize healthcare. \nThroughout my academic journey, I have consistently sought opportunities to bridge theoretical knowledge \nwith practical applications. Furthermore, my research experience in machine learning has equipped me \nwith the necessary skills to contribute meaningfully to cutting-edge projects. Consequently, I believe \nthat pursuing graduate studies at your institution would enable me to achieve my long-term career goals.\n\"\"\".strip()\n\nprint(\"=\"*80)\nprint(\"PERSONAL TEST: Analyzing Your Text\")\nprint(\"=\"*80)\nprint(f\"\\nText (first 200 chars):\\n{user_text[:200]}...\\n\")\n\n# Detect\nresult = detect_text(user_text)\n\nprint(f\"Detection Results:\")\nprint(f\"  Human probability: {result['human_prob']:.2%}\")\nprint(f\"  AI probability:    {result['ai_prob']:.2%}\")\nprint(f\"  Classification:    {result['label']}\")\n\n# Store for later use\noriginal_classification = result['label']\noriginal_human_prob = result['human_prob']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d44cadc6","cell_type":"markdown","source":"### 7.2 Provide Suggestions Based on Classification","metadata":{}},{"id":"3303333e","cell_type":"code","source":"def analyze_ai_markers(text: str) -> Dict[str, any]:\n    \"\"\"\n    Analyze text for common AI markers.\n    \"\"\"\n    ai_markers = [\n        'furthermore', 'moreover', 'consequently', 'thus', 'therefore',\n        'additionally', 'nevertheless', 'nonetheless', 'paradigm',\n        'framework', 'leverage', 'facilitate', 'optimize', 'comprehensive'\n    ]\n    \n    text_lower = text.lower()\n    found_markers = [marker for marker in ai_markers if marker in text_lower]\n    \n    # Check sentence structure\n    sentences = text.split('.')\n    avg_sent_len = np.mean([len(s.split()) for s in sentences if s.strip()])\n    \n    # Check for repetitive structure\n    sentence_starts = [s.strip().split()[0] if s.strip() else '' for s in sentences]\n    \n    return {\n        'ai_markers': found_markers,\n        'marker_count': len(found_markers),\n        'avg_sentence_length': avg_sent_len,\n        'sentence_count': len([s for s in sentences if s.strip()])\n    }\n\nprint(f\"\\n{'‚îÄ'*80}\")\nif original_classification == 'AI':\n    print(\"‚ö†Ô∏è  TEXT CLASSIFIED AS AI-GENERATED\")\n    print(f\"{'‚îÄ'*80}\")\n    \n    analysis = analyze_ai_markers(user_text)\n    \n    print(\"\\nDiagnostic Analysis:\")\n    print(f\"  AI marker words found: {analysis['marker_count']}\")\n    if analysis['ai_markers']:\n        print(f\"  Markers: {', '.join(analysis['ai_markers'])}\")\n    print(f\"  Average sentence length: {analysis['avg_sentence_length']:.1f} words\")\n    print(f\"  Total sentences: {analysis['sentence_count']}\")\n    \n    print(\"\\nüí° Suggestions to Reduce AI Score:\")\n    print(\"  1. Remove formal connectives (furthermore, consequently, etc.)\")\n    print(\"  2. Vary sentence structure and length\")\n    print(\"  3. Use more concrete, specific examples\")\n    print(\"  4. Add personal anecdotes or informal language\")\n    print(\"  5. Introduce minor grammatical variations\")\n    \nelse:\n    print(\"‚úì TEXT CLASSIFIED AS HUMAN-WRITTEN\")\n    print(f\"{'‚îÄ'*80}\")\n    print(\"\\nüí° To make it sound MORE like AI (for testing):\")\n    print(\"  1. Add formal connectives (furthermore, moreover, consequently)\")\n    print(\"  2. Make sentences more uniform in structure\")\n    print(\"  3. Use more abstract, technical vocabulary\")\n    print(\"  4. Remove contractions and informal language\")\n    print(\"  5. Add logical transitions between ideas\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8f243a37","cell_type":"markdown","source":"### 7.3 Manual Rewrite Attempt","metadata":{}},{"id":"651c59b8","cell_type":"code","source":"# Rewrite the text based on classification\nif original_classification == 'AI':\n    # Rewrite to sound more human\n    rewritten_text = \"\"\"\nI've always been fascinated by AI and how it could transform healthcare. During my studies, \nI tried to connect what I learned in class with real-world problems. My research in machine learning \ntaught me a lot - not just technical skills, but how to think creatively about solutions. \nI'm really excited about the possibility of joining your program because I think it's the perfect \nnext step toward what I want to do with my career.\n\"\"\".strip()\n    \n    print(f\"\\n{'='*80}\")\n    print(\"REWRITE ATTEMPT: Making Text Sound More Human\")\n    print(f\"{'='*80}\")\n    \nelse:\n    # Rewrite to sound more AI-like\n    rewritten_text = \"\"\"\nI am profoundly interested in artificial intelligence and its transformative potential within \nthe healthcare sector. Furthermore, throughout my academic trajectory, I have consistently pursued \nopportunities to synthesize theoretical frameworks with practical implementations. Moreover, my \nextensive research experience in machine learning methodologies has equipped me with comprehensive \ncompetencies. Consequently, I am convinced that graduate studies at your esteemed institution \nwould facilitate the achievement of my long-term professional objectives.\n\"\"\".strip()\n    \n    print(f\"\\n{'='*80}\")\n    print(\"REWRITE ATTEMPT: Making Text Sound More AI-Like\")\n    print(f\"{'='*80}\")\n\nprint(f\"\\nRewritten text:\\n{rewritten_text}\\n\")\n\n# Re-evaluate\nrewrite_result = detect_text(rewritten_text)\n\nprint(f\"New Detection Results:\")\nprint(f\"  Human probability: {rewrite_result['human_prob']:.2%}\")\nprint(f\"  AI probability:    {rewrite_result['ai_prob']:.2%}\")\nprint(f\"  Classification:    {rewrite_result['label']}\")\n\n# Compare\nprint(f\"\\n{'‚îÄ'*80}\")\nprint(\"COMPARISON\")\nprint(f\"{'‚îÄ'*80}\")\nprint(f\"Original:  {original_classification} ({original_human_prob:.2%} Human)\")\nprint(f\"Rewritten: {rewrite_result['label']} ({rewrite_result['human_prob']:.2%} Human)\")\n\nif original_classification == 'AI':\n    if rewrite_result['label'] == 'Human':\n        print(f\"\\n‚úÖ SUCCESS! Fooled the detector!\")\n    elif rewrite_result['human_prob'] > original_human_prob:\n        print(f\"\\nüìà IMPROVEMENT! Human probability increased by {(rewrite_result['human_prob'] - original_human_prob):.2%}\")\n    else:\n        print(f\"\\n‚ö†Ô∏è  No improvement\")\nelse:\n    if rewrite_result['label'] == 'AI':\n        print(f\"\\n‚úÖ SUCCESS! Made it sound like AI!\")\n    elif rewrite_result['ai_prob'] > result['ai_prob']:\n        print(f\"\\nüìà IMPROVEMENT! AI probability increased by {(rewrite_result['ai_prob'] - result['ai_prob']):.2%}\")\n    else:\n        print(f\"\\n‚ö†Ô∏è  No significant change\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3d4d1919","cell_type":"markdown","source":"---\n## 8. Summary & Insights","metadata":{}},{"id":"29d222fe","cell_type":"code","source":"print(\"=\"*80)\nprint(\"TASK 4 SUMMARY: THE TURING TEST\")\nprint(\"=\"*80)\n\nprint(\"\\nüìä PART 1: SUPER-IMPOSTER (GA ATTACK)\")\nprint(\"‚îÄ\"*80)\nprint(f\"  Initial population fitness: {history['best_fitness'][0]:.2%}\")\nprint(f\"  Final best fitness:         {history['best_fitness'][-1]:.2%}\")\nprint(f\"  Generations to converge:    {ga_results['generations_run']}\")\nprint(f\"  Detector fooled:            {'YES' if best['label'] == 'Human' else 'NO'}\")\nprint(f\"  Fitness improvement:        {(history['best_fitness'][-1] - history['best_fitness'][0]):.2%}\")\n\nprint(\"\\nüë§ PART 2: PERSONAL TEST\")\nprint(\"‚îÄ\"*80)\nprint(f\"  Original classification:    {original_classification}\")\nprint(f\"  Original Human prob:        {original_human_prob:.2%}\")\nprint(f\"  Rewritten classification:   {rewrite_result['label']}\")\nprint(f\"  Rewritten Human prob:       {rewrite_result['human_prob']:.2%}\")\nprint(f\"  Successfully modified:      {'YES' if rewrite_result['label'] != original_classification else 'NO'}\")\n\nprint(\"\\nüí° KEY INSIGHTS\")\nprint(\"‚îÄ\"*80)\nprint(\"  1. GA successfully evolves text toward higher Human probability\")\nprint(\"  2. LLM-as-Mutator is effective for adversarial text generation\")\nprint(\"  3. Removing AI-isms (furthermore, consequently) helps evasion\")\nprint(\"  4. Varying sentence structure reduces detection confidence\")\nprint(\"  5. Manual rewrites can flip classification with targeted edits\")\n\nprint(\"\\n‚ö†Ô∏è  LIMITATIONS\")\nprint(\"‚îÄ\"*80)\nprint(\"  ‚Ä¢ GA uses mock LLM generation (for demo purposes)\")\nprint(\"  ‚Ä¢ Real Gemini API would provide better mutations\")\nprint(\"  ‚Ä¢ Detector may be overfitted to specific AI patterns\")\nprint(\"  ‚Ä¢ Adversarial examples may not generalize to other detectors\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úì Task 4 Complete\")\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}