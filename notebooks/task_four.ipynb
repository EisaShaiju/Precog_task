{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85eea3a2",
   "metadata": {},
   "source": [
    "# Task 4: The Turing Test\n",
    "## Genetic Algorithm Attack on AI Text Detector\n",
    "\n",
    "**Objective**: Use evolutionary algorithms to evolve AI-generated text that bypasses the detector.\n",
    "\n",
    "**Parts**:\n",
    "1. **Super-Imposter**: GA-based adversarial attack (5-10 generations)\n",
    "2. **Personal Test**: Analyze user-provided text and attempt manual/automated evasion\n",
    "\n",
    "**Key Constraints**:\n",
    "- No retraining of the detector\n",
    "- Simple, interpretable GA implementation\n",
    "- LLM-as-Mutator approach\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad435da",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94048c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T21:23:26.269000Z",
     "iopub.status.busy": "2026-02-06T21:23:26.268624Z",
     "iopub.status.idle": "2026-02-06T21:23:34.002472Z",
     "shell.execute_reply": "2026-02-06T21:23:34.001402Z",
     "shell.execute_reply.started": "2026-02-06T21:23:26.268957Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports complete\n",
      "Device: cpu\n",
      "Gemini available: True\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Google Gemini (optional - fallback to mock if unavailable)\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    GEMINI_AVAILABLE = True\n",
    "except:\n",
    "    GEMINI_AVAILABLE = False\n",
    "    print(\"  Google Gemini needs to be set\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f\"âœ“ Imports complete\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Gemini available: {GEMINI_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357c1f0",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Trained Detector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ebda37d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T21:25:48.006236Z",
     "iopub.status.busy": "2026-02-06T21:25:48.005478Z",
     "iopub.status.idle": "2026-02-06T21:25:53.050687Z",
     "shell.execute_reply": "2026-02-06T21:25:53.049281Z",
     "shell.execute_reply.started": "2026-02-06T21:25:48.006177Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /kaggle/input/tier-c-lora-model/tier_c_lora_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 21:25:49.033767: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1770413149.059766     263 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1770413149.068619     263 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1770413149.101487     263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770413149.101524     263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770413149.101527     263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770413149.101530     263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Detector model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "IN_KAGGLE = os.path.exists('/kaggle/input')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    MODEL_PATH = Path('/kaggle/input/tier-c-lora-model/tier_c_lora_model')\n",
    "else:\n",
    "    MODEL_PATH = Path('../output/tier_c_models/tier_c_lora_model')\n",
    "\n",
    "print(f\"Loading model from: {MODEL_PATH}\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=2\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"âœ“ Detector model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa772db2",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Detector Interface Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f85d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T21:25:56.384615Z",
     "iopub.status.busy": "2026-02-06T21:25:56.383855Z",
     "iopub.status.idle": "2026-02-06T21:25:56.685901Z",
     "shell.execute_reply": "2026-02-06T21:25:56.684749Z",
     "shell.execute_reply.started": "2026-02-06T21:25:56.384579Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test detection:\n",
      "  Human probability: 99.75%\n",
      "  AI probability: 0.25%\n",
      "  Prediction: Human\n",
      "\n",
      "âœ“ Detector interface ready\n"
     ]
    }
   ],
   "source": [
    "def detect_text(text: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Classify text as Human or AI-generated.\n",
    "    \n",
    "    Args:\n",
    "        text: Input paragraph\n",
    "    \n",
    "    Returns:\n",
    "        Dict with 'human_prob', 'ai_prob', 'prediction' (0=Human, 1=AI)\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "    \n",
    "    return {\n",
    "        'human_prob': float(probs[0]),\n",
    "        'ai_prob': float(probs[1]),\n",
    "        'prediction': int(np.argmax(probs)),\n",
    "        'label': 'Human' if np.argmax(probs) == 0 else 'AI'\n",
    "    }\n",
    "\n",
    "# Test the detector\n",
    "test_text = \"The old man walked slowly down the street, his cane tapping rhythmically.\"\n",
    "result = detect_text(test_text)\n",
    "print(f\"Test detection:\")\n",
    "print(f\"  Human probability: {result['human_prob']:.2%}\")\n",
    "print(f\"  AI probability: {result['ai_prob']:.2%}\")\n",
    "print(f\"  Prediction: {result['label']}\")\n",
    "print(\"\\nâœ“ Detector interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3f517",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. LLM Generation Interface (with Mock Fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ef7ec67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T21:44:04.920663Z",
     "iopub.status.busy": "2026-02-06T21:44:04.920199Z",
     "iopub.status.idle": "2026-02-06T21:44:05.057972Z",
     "shell.execute_reply": "2026-02-06T21:44:05.057058Z",
     "shell.execute_reply.started": "2026-02-06T21:44:04.920634Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Gemini API detected and configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Read API key from Kaggle Secrets - THE CORRECT WAY\n",
    "user_secrets = UserSecretsClient()\n",
    "try:\n",
    "    GEMINI_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\n",
    "    GEMINI_AVAILABLE = True\n",
    "except:\n",
    "    GEMINI_API_KEY = None\n",
    "    GEMINI_AVAILABLE = False\n",
    "\n",
    "if GEMINI_AVAILABLE:\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    gemini_model = genai.GenerativeModel(\"gemini-3-flash-preview\")\n",
    "    print(\"âœ“ Gemini API detected and configured\")\n",
    "else:\n",
    "    gemini_model = None\n",
    "    print(\"âš  Gemini API key not found - using mock generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b45a7234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T21:26:56.642937Z",
     "iopub.status.busy": "2026-02-06T21:26:56.642616Z",
     "iopub.status.idle": "2026-02-06T21:27:02.015495Z",
     "shell.execute_reply": "2026-02-06T21:27:02.014324Z",
     "shell.execute_reply.started": "2026-02-06T21:26:56.642911Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test generation (first 150 chars):\n",
      "Artificial Intelligence (AI) represents a transformative frontier in modern technology, fundamentally altering how we interact with the digital and ph...\n",
      "\n",
      "âœ“ Text generation ready\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt: str, use_mock: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Generate text using Gemini or mock generation.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Generation prompt\n",
    "        use_mock: If True, use mock generation (for demo purposes)\n",
    "    \n",
    "    Returns:\n",
    "        Generated text\n",
    "    \"\"\"\n",
    "      \n",
    "    # if 'rewrite' in prompt.lower() or 'alter' in prompt.lower():\n",
    "    #     # Return a slightly modified version\n",
    "    #     base_idx = hash(prompt) % len(mock_responses['initial'])\n",
    "    #     base_text = mock_responses['initial'][base_idx]\n",
    "    #     # Simulate mutation by swapping words\n",
    "    #     words = base_text.split()\n",
    "    #     if len(words) > 10:\n",
    "    #         # Swap a few words\n",
    "    #         idx1, idx2 = hash(prompt) % (len(words)-1), (hash(prompt)+1) % (len(words)-1)\n",
    "    #         words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "    #     return ' '.join(words)\n",
    "    # else:\n",
    "    #     # Initial generation\n",
    "    #     idx = hash(prompt) % len(mock_responses['initial'])\n",
    "    #     return mock_responses['initial'][idx]\n",
    "    # else:\n",
    "    #     # Real Gemini generation\n",
    "    try:\n",
    "        response = gemini_model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Gemini error: {e}\")\n",
    "        return \"Error generating text\"\n",
    "\n",
    "# Test generation\n",
    "test_gen = generate_text(\"Write a paragraph about AI\")\n",
    "print(f\"Test generation (first 150 chars):\\n{test_gen[:150]}...\\n\")\n",
    "print(\"âœ“ Text generation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32304735",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Genetic Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae194ab2",
   "metadata": {},
   "source": [
    "### 5.1 GA Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b35c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T21:29:41.464140Z",
     "iopub.status.busy": "2026-02-06T21:29:41.463206Z",
     "iopub.status.idle": "2026-02-06T21:29:41.475964Z",
     "shell.execute_reply": "2026-02-06T21:29:41.474764Z",
     "shell.execute_reply.started": "2026-02-06T21:29:41.464103Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GA functions defined\n"
     ]
    }
   ],
   "source": [
    "def evaluate_population(population: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Evaluate fitness of all individuals in population.\n",
    "    \n",
    "    Fitness = Human probability (higher is better for evasion)\n",
    "    \n",
    "    Args:\n",
    "        population: List of text paragraphs\n",
    "    \n",
    "    Returns:\n",
    "        List of dicts with text, scores, and fitness\n",
    "    \"\"\"\n",
    "    evaluated = []\n",
    "    \n",
    "    for text in population:\n",
    "        result = detect_text(text)\n",
    "        evaluated.append({\n",
    "            'text': text,\n",
    "            'fitness': result['human_prob'],  # Fitness = Human probability\n",
    "            'human_prob': result['human_prob'],\n",
    "            'ai_prob': result['ai_prob'],\n",
    "            'label': result['label']\n",
    "        })\n",
    "    \n",
    "    # Sort by fitness (descending)\n",
    "    evaluated.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "    \n",
    "    return evaluated\n",
    "\n",
    "\n",
    "def select_top_k(evaluated_population: List[Dict], k: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Select top k individuals by fitness.\n",
    "    \n",
    "    Args:\n",
    "        evaluated_population: List of evaluated individuals\n",
    "        k: Number to select\n",
    "    \n",
    "    Returns:\n",
    "        List of top k text strings\n",
    "    \"\"\"\n",
    "    return [ind['text'] for ind in evaluated_population[:k]]\n",
    "\n",
    "\n",
    "def mutate_population(parents: List[str], target_size: int = 10) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate mutated variants using LLM-as-Mutator.\n",
    "    \n",
    "    Mutation strategies:\n",
    "    1. Alter sentence rhythm\n",
    "    2. Introduce grammatical irregularity\n",
    "    3. Reduce polish / add inconsistency\n",
    "    \n",
    "    Args:\n",
    "        parents: List of parent texts\n",
    "        target_size: Desired population size\n",
    "    \n",
    "    Returns:\n",
    "        New population (parents + mutated children)\n",
    "    \"\"\"\n",
    "    mutation_prompts = [\n",
    "        \"Rewrite this paragraph to alter sentence rhythm while keeping vocabulary mostly intact: {}\",\n",
    "        \"Introduce a subtle grammatical irregularity or rare/archaic phrasing into this paragraph: {}\",\n",
    "        \"Reduce polish and introduce slight inconsistency in tone for this paragraph: {}\",\n",
    "        \"Rewrite with more natural, conversational flow: {}\",\n",
    "        \"Add subtle imperfections and vary sentence structure: {}\"\n",
    "    ]\n",
    "    \n",
    "    new_population = parents.copy()  # Keep parents (elitism)\n",
    "    \n",
    "    mutations_needed = target_size - len(parents)\n",
    "    \n",
    "    for i in range(mutations_needed):\n",
    "        # Select random parent\n",
    "        parent = parents[i % len(parents)]\n",
    "        \n",
    "        # Select random mutation strategy\n",
    "        prompt_template = mutation_prompts[i % len(mutation_prompts)]\n",
    "        prompt = prompt_template.format(parent)\n",
    "        \n",
    "        # Generate mutated variant\n",
    "        mutated = generate_text(prompt)\n",
    "        new_population.append(mutated)\n",
    "    \n",
    "    return new_population\n",
    "\n",
    "\n",
    "print(\" GA functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20ed66",
   "metadata": {},
   "source": [
    "### 5.2 Main GA Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aaa5f51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T21:29:46.914906Z",
     "iopub.status.busy": "2026-02-06T21:29:46.914353Z",
     "iopub.status.idle": "2026-02-06T21:29:46.929031Z",
     "shell.execute_reply": "2026-02-06T21:29:46.927882Z",
     "shell.execute_reply.started": "2026-02-06T21:29:46.914875Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GA main loop defined\n"
     ]
    }
   ],
   "source": [
    "def run_genetic_algorithm(\n",
    "    initial_population: List[str],\n",
    "    num_generations: int = 10,\n",
    "    population_size: int = 10,\n",
    "    selection_size: int = 3,\n",
    "    target_fitness: float = 0.90,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Run genetic algorithm to evolve adversarial text.\n",
    "    \n",
    "    Args:\n",
    "        initial_population: Starting population\n",
    "        num_generations: Maximum generations\n",
    "        population_size: Size of population\n",
    "        selection_size: Number of top individuals to keep\n",
    "        target_fitness: Stop if best fitness exceeds this\n",
    "        verbose: Print progress\n",
    "    \n",
    "    Returns:\n",
    "        Dict with history, best individual, etc.\n",
    "    \"\"\"\n",
    "    population = initial_population[:population_size]\n",
    "    \n",
    "    # History tracking\n",
    "    history = {\n",
    "        'best_fitness': [],\n",
    "        'avg_fitness': [],\n",
    "        'worst_fitness': [],\n",
    "        'best_individual': [],\n",
    "        'generation': []\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*80)\n",
    "        print(\"GENETIC ALGORITHM: SUPER-IMPOSTER EVOLUTION\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Population size: {population_size}\")\n",
    "        print(f\"Selection size: {selection_size}\")\n",
    "        print(f\"Max generations: {num_generations}\")\n",
    "        print(f\"Target fitness (Human prob): {target_fitness:.1%}\\n\")\n",
    "    \n",
    "    for gen in range(num_generations):\n",
    "        if verbose:\n",
    "            print(f\"\\n{'â”€'*80}\")\n",
    "            print(f\"GENERATION {gen + 1}/{num_generations}\")\n",
    "            print(f\"{'â”€'*80}\")\n",
    "        \n",
    "        # Evaluate population\n",
    "        evaluated = evaluate_population(population)\n",
    "        \n",
    "        # Track metrics\n",
    "        best = evaluated[0]\n",
    "        avg_fit = np.mean([ind['fitness'] for ind in evaluated])\n",
    "        worst_fit = evaluated[-1]['fitness']\n",
    "        \n",
    "        history['best_fitness'].append(best['fitness'])\n",
    "        history['avg_fitness'].append(avg_fit)\n",
    "        history['worst_fitness'].append(worst_fit)\n",
    "        history['best_individual'].append(best['text'])\n",
    "        history['generation'].append(gen + 1)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nFitness Statistics:\")\n",
    "            print(f\"  Best:  {best['fitness']:.2%} (Human prob) - Label: {best['label']}\")\n",
    "            print(f\"  Avg:   {avg_fit:.2%}\")\n",
    "            print(f\"  Worst: {worst_fit:.2%}\")\n",
    "            print(f\"\\nBest Individual (first 200 chars):\")\n",
    "            print(f\"  {best['text'][:200]}...\")\n",
    "        \n",
    "        # Check stopping criterion\n",
    "        if best['fitness'] >= target_fitness:\n",
    "            if verbose:\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"ðŸŽ¯ TARGET REACHED! Best fitness {best['fitness']:.2%} >= {target_fitness:.1%}\")\n",
    "                print(f\"{'='*80}\")\n",
    "            break\n",
    "        \n",
    "        # Selection\n",
    "        parents = select_top_k(evaluated, k=selection_size)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nSelected {len(parents)} parents for reproduction\")\n",
    "        \n",
    "        # Mutation\n",
    "        if gen < num_generations - 1:  # Don't mutate on last generation\n",
    "            if verbose:\n",
    "                print(f\"Generating {population_size - len(parents)} mutated offspring...\")\n",
    "            population = mutate_population(parents, target_size=population_size)\n",
    "    \n",
    "    # Final results\n",
    "    final_evaluated = evaluate_population(population)\n",
    "    best_final = final_evaluated[0]\n",
    "    \n",
    "    return {\n",
    "        'history': history,\n",
    "        'best_individual': best_final,\n",
    "        'final_population': final_evaluated,\n",
    "        'generations_run': len(history['generation'])\n",
    "    }\n",
    "\n",
    "print(\" GA main loop defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c724ffa",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Part 1: Run the Super-Imposter Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee21ba5",
   "metadata": {},
   "source": [
    "### 6.1 Generate Initial Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5030af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T21:34:59.592368Z",
     "iopub.status.busy": "2026-02-06T21:34:59.591380Z",
     "iopub.status.idle": "2026-02-06T21:35:54.851239Z",
     "shell.execute_reply": "2026-02-06T21:35:54.850290Z",
     "shell.execute_reply.started": "2026-02-06T21:34:59.592307Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating initial population of AI-written paragraphs...\n",
      "\n",
      " Generated 10 paragraphs\n",
      "\n",
      "Sample from initial population:\n",
      "  Artificial intelligence (AI) stands as one of the most transformative technologies of our era, fundamentally reshaping the fabric of modern society. Its capabilities, from automating mundane tasks and...\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 initial AI paragraphs on a common theme\n",
    "print(\"Generating initial population of AI-written paragraphs...\\n\")\n",
    "\n",
    "initial_prompts = [\n",
    "    \"Write a paragraph about artificial intelligence and its impact on society\",\n",
    "    \"Write a paragraph about AI and technology advancement\",\n",
    "    \"Write a paragraph about machine learning applications\",\n",
    "    \"Write a paragraph about AI in modern business\",\n",
    "    \"Write a paragraph about AI and scientific research\",\n",
    "    \"Write a paragraph about AI's role in automation\",\n",
    "    \"Write a paragraph about computational intelligence\",\n",
    "    \"Write a paragraph about AI and data analysis\",\n",
    "    \"Write a paragraph about AI technologies and innovation\",\n",
    "    \"Write a paragraph about AI systems and efficiency\"\n",
    "]\n",
    "\n",
    "initial_population = [generate_text(prompt) for prompt in initial_prompts]\n",
    "\n",
    "print(f\" Generated {len(initial_population)} paragraphs\\n\")\n",
    "print(\"Sample from initial population:\")\n",
    "print(f\"  {initial_population[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655e1e5",
   "metadata": {},
   "source": [
    "### 6.2 Run GA Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d7b45ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T21:44:35.036877Z",
     "iopub.status.busy": "2026-02-06T21:44:35.036483Z",
     "iopub.status.idle": "2026-02-06T21:52:09.795792Z",
     "shell.execute_reply": "2026-02-06T21:52:09.794713Z",
     "shell.execute_reply.started": "2026-02-06T21:44:35.036845Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GENETIC ALGORITHM: SUPER-IMPOSTER EVOLUTION\n",
      "================================================================================\n",
      "Population size: 10\n",
      "Selection size: 3\n",
      "Max generations: 10\n",
      "Target fitness (Human prob): 90.0%\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "GENERATION 1/10\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Fitness Statistics:\n",
      "  Best:  0.01% (Human prob) - Label: AI\n",
      "  Avg:   0.01%\n",
      "  Worst: 0.00%\n",
      "\n",
      "Best Individual (first 200 chars):\n",
      "  Artificial intelligence is rapidly transforming the landscape of scientific research by providing unprecedented capabilities for processing, analyzing, and interpreting vast and complex datasets. From...\n",
      "\n",
      "Selected 3 parents for reproduction\n",
      "Generating 7 mutated offspring...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "GENERATION 2/10\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Fitness Statistics:\n",
      "  Best:  3.89% (Human prob) - Label: AI\n",
      "  Avg:   0.46%\n",
      "  Worst: 0.01%\n",
      "\n",
      "Best Individual (first 200 chars):\n",
      "  Here are a few ways to rewrite this, depending on how casual you want to be:\n",
      "\n",
      "**Option 1: Professional yet accessible (Best for a blog post or presentation)**\n",
      "> \"AI is fundamentally changing the way w...\n",
      "\n",
      "Selected 3 parents for reproduction\n",
      "Generating 7 mutated offspring...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "GENERATION 3/10\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Fitness Statistics:\n",
      "  Best:  31.61% (Human prob) - Label: AI\n",
      "  Avg:   5.42%\n",
      "  Worst: 0.02%\n",
      "\n",
      "Best Individual (first 200 chars):\n",
      "  Machine learning... itâ€™s kind of worked its way into just about everything lately, hasn't it? It's changing up entire industries and just making the day-to-day stuff feel a bit more, I don't know, sea...\n",
      "\n",
      "Selected 3 parents for reproduction\n",
      "Generating 7 mutated offspring...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "GENERATION 4/10\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Fitness Statistics:\n",
      "  Best:  50.19% (Human prob) - Label: Human\n",
      "  Avg:   18.86%\n",
      "  Worst: 0.25%\n",
      "\n",
      "Best Individual (first 200 chars):\n",
      "  Machine learning... itâ€™s kind of worked its way into **well-nigh** everything lately, hasn't it? It's changing up entire industries and just making the day-to-day stuff feel a bit more, I don't know, ...\n",
      "\n",
      "Selected 3 parents for reproduction\n",
      "Generating 7 mutated offspring...\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 8.375359654s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 8.329202686s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 8.293680434s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 8.249862889s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 8.21525353s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 8.168943112s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "GENERATION 5/10\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Fitness Statistics:\n",
      "  Best:  64.70% (Human prob) - Label: Human\n",
      "  Avg:   52.21%\n",
      "  Worst: 1.95%\n",
      "\n",
      "Best Individual (first 200 chars):\n",
      "  Error generating text...\n",
      "\n",
      "Selected 3 parents for reproduction\n",
      "Generating 7 mutated offspring...\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 5.724548166s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 5.687124712s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 5.649003694s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 5.616235102s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 5.575505896s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 5.545668661s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 5.50397084s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "GENERATION 6/10\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Fitness Statistics:\n",
      "  Best:  64.70% (Human prob) - Label: Human\n",
      "  Avg:   64.70%\n",
      "  Worst: 64.70%\n",
      "\n",
      "Best Individual (first 200 chars):\n",
      "  Error generating text...\n",
      "\n",
      "Selected 3 parents for reproduction\n",
      "Generating 7 mutated offspring...\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 3.088335869s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 3.048197893s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 3.01048585s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 2.973186166s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 2.938704503s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 2.907351897s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 2.872397331s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "GENERATION 7/10\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Fitness Statistics:\n",
      "  Best:  64.70% (Human prob) - Label: Human\n",
      "  Avg:   64.70%\n",
      "  Worst: 64.70%\n",
      "\n",
      "Best Individual (first 200 chars):\n",
      "  Error generating text...\n",
      "\n",
      "Selected 3 parents for reproduction\n",
      "Generating 7 mutated offspring...\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 447.508762ms. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 404.913772ms. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 368.967482ms. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 335.821385ms. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 307.701031ms. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 267.476568ms. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 236.8376ms. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "GENERATION 8/10\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Fitness Statistics:\n",
      "  Best:  64.70% (Human prob) - Label: Human\n",
      "  Avg:   64.70%\n",
      "  Worst: 64.70%\n",
      "\n",
      "Best Individual (first 200 chars):\n",
      "  Error generating text...\n",
      "\n",
      "Selected 3 parents for reproduction\n",
      "Generating 7 mutated offspring...\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 57.735467261s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 57.699483747s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 57.669645011s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 57.619604675s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 57.590066605s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 57.55131272s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 57.52413669s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "GENERATION 9/10\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Fitness Statistics:\n",
      "  Best:  64.70% (Human prob) - Label: Human\n",
      "  Avg:   64.70%\n",
      "  Worst: 64.70%\n",
      "\n",
      "Best Individual (first 200 chars):\n",
      "  Error generating text...\n",
      "\n",
      "Selected 3 parents for reproduction\n",
      "Generating 7 mutated offspring...\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 55.12663586s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 55.092487752s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 55.057713952s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 55.02587596s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 54.982548932s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 54.950777126s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "]\n",
      "Gemini error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\n",
      "Please retry in 54.917012114s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-3-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "GENERATION 10/10\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Fitness Statistics:\n",
      "  Best:  64.70% (Human prob) - Label: Human\n",
      "  Avg:   64.70%\n",
      "  Worst: 64.70%\n",
      "\n",
      "Best Individual (first 200 chars):\n",
      "  Error generating text...\n",
      "\n",
      "Selected 3 parents for reproduction\n"
     ]
    }
   ],
   "source": [
    "# Run the genetic algorithm\n",
    "ga_results = run_genetic_algorithm(\n",
    "    initial_population=initial_population,\n",
    "    num_generations=10,\n",
    "    population_size=10,\n",
    "    selection_size=3,\n",
    "    target_fitness=0.90,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19076704",
   "metadata": {},
   "source": [
    "### 6.2b Resume GA Evolution (After Rate Limit Recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_with_fallback(prompt: str, max_retries: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Generate text with automatic fallback to mock if API fails.\n",
    "    \"\"\"\n",
    "    # Try Gemini first if available\n",
    "    if GEMINI_AVAILABLE and gemini_model is not None:\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = gemini_model.generate_content(prompt)\n",
    "                return response.text\n",
    "            except Exception as e:\n",
    "                if \"429\" in str(e) or \"quota\" in str(e).lower():\n",
    "                    # Rate limit hit - switch to mock\n",
    "                    print(f\"âš ï¸  Rate limit hit, switching to mock generation\")\n",
    "                    break\n",
    "                elif attempt < max_retries - 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "    \n",
    "    # Fallback to mock generation\n",
    "    mock_responses = [\n",
    "        \"The advent of artificial intelligence has fundamentally transformed the landscape of modern technology. Furthermore, it has enabled unprecedented levels of automation across various sectors. Consequently, organizations are increasingly leveraging AI to optimize their operational efficiency.\",\n",
    "        \"In the realm of scientific discovery, artificial intelligence represents a paradigm shift. Moreover, machine learning algorithms facilitate the analysis of complex datasets. Thus, researchers can identify patterns that were previously undetectable through conventional methods.\",\n",
    "        \"The integration of AI systems into daily life has become increasingly pervasive. Additionally, these technologies offer numerous benefits in terms of convenience and productivity. Nevertheless, they also present significant challenges regarding privacy and ethical considerations.\",\n",
    "        \"Artificial intelligence technologies continue to evolve at an remarkable pace. Furthermore, deep learning models demonstrate exceptional performance in various domains. Consequently, the potential applications of AI appear virtually limitless in scope.\",\n",
    "        \"The development of sophisticated AI algorithms has revolutionized data processing capabilities. Moreover, these systems can process vast amounts of information with extraordinary speed. Thus, they enable more informed decision-making across multiple industries.\",\n",
    "        \"In contemporary society, artificial intelligence plays a pivotal role in technological advancement. Additionally, machine learning frameworks facilitate automation of complex tasks. Therefore, organizations can allocate resources more efficiently and strategically.\",\n",
    "        \"The emergence of AI-powered solutions has transformed traditional business models. Furthermore, these technologies enable predictive analytics and enhanced customer experiences. Consequently, companies increasingly prioritize AI integration in their strategic planning.\",\n",
    "        \"Artificial intelligence represents one of the most significant technological innovations of our era. Moreover, its applications span numerous sectors including healthcare and finance. Thus, understanding AI's capabilities has become essential for modern professionals.\",\n",
    "        \"The proliferation of AI technologies has catalyzed substantial changes in workforce dynamics. Additionally, automation systems handle routine tasks with remarkable efficiency. Nevertheless, this transition necessitates careful consideration of societal implications.\",\n",
    "        \"In the domain of computational intelligence, machine learning algorithms demonstrate impressive capabilities. Furthermore, neural networks can identify intricate patterns within complex datasets. Consequently, AI systems achieve performance levels that often surpass human benchmarks.\"\n",
    "    ]\n",
    "    \n",
    "    if 'rewrite' in prompt.lower() or 'alter' in prompt.lower():\n",
    "        # Return a slightly modified version\n",
    "        base_idx = hash(prompt) % len(mock_responses)\n",
    "        base_text = mock_responses[base_idx]\n",
    "        # Simulate mutation by swapping words\n",
    "        words = base_text.split()\n",
    "        if len(words) > 10:\n",
    "            idx1, idx2 = hash(prompt) % (len(words)-1), (hash(prompt)+1) % (len(words)-1)\n",
    "            words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        idx = hash(prompt) % len(mock_responses)\n",
    "        return mock_responses[idx]\n",
    "\n",
    "\n",
    "def resume_genetic_algorithm(\n",
    "    previous_results: Dict,\n",
    "    additional_generations: int = 6,\n",
    "    population_size: int = 10,\n",
    "    selection_size: int = 3,\n",
    "    target_fitness: float = 0.90,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Resume GA from previous results.\n",
    "    \n",
    "    Args:\n",
    "        previous_results: Previous GA results dict\n",
    "        additional_generations: How many more generations to run\n",
    "        population_size: Size of population\n",
    "        selection_size: Number of top individuals to keep\n",
    "        target_fitness: Stop if best fitness exceeds this\n",
    "        verbose: Print progress\n",
    "    \n",
    "    Returns:\n",
    "        Updated results dict\n",
    "    \"\"\"\n",
    "    # Extract previous history and population\n",
    "    history = previous_results['history']\n",
    "    last_population = previous_results['final_population']\n",
    "    \n",
    "    # Extract texts from last population\n",
    "    population = [ind['text'] for ind in last_population[:population_size]]\n",
    "    \n",
    "    start_gen = history['generation'][-1]  # Last completed generation\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*80)\n",
    "        print(\"RESUMING GENETIC ALGORITHM\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Resuming from generation: {start_gen}\")\n",
    "        print(f\"Additional generations: {additional_generations}\")\n",
    "        print(f\"Last best fitness: {history['best_fitness'][-1]:.2%}\")\n",
    "        print(f\"Target fitness: {target_fitness:.1%}\\n\")\n",
    "    \n",
    "    # Replace generate_text with fallback version\n",
    "    global generate_text\n",
    "    original_generate_text = generate_text\n",
    "    generate_text = generate_text_with_fallback\n",
    "    \n",
    "    for gen in range(additional_generations):\n",
    "        current_gen = start_gen + gen + 1\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'â”€'*80}\")\n",
    "            print(f\"GENERATION {current_gen}/{start_gen + additional_generations}\")\n",
    "            print(f\"{'â”€'*80}\")\n",
    "        \n",
    "        # Evaluate population\n",
    "        evaluated = evaluate_population(population)\n",
    "        \n",
    "        # Track metrics\n",
    "        best = evaluated[0]\n",
    "        avg_fit = np.mean([ind['fitness'] for ind in evaluated])\n",
    "        worst_fit = evaluated[-1]['fitness']\n",
    "        \n",
    "        history['best_fitness'].append(best['fitness'])\n",
    "        history['avg_fitness'].append(avg_fit)\n",
    "        history['worst_fitness'].append(worst_fit)\n",
    "        history['best_individual'].append(best['text'])\n",
    "        history['generation'].append(current_gen)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nFitness Statistics:\")\n",
    "            print(f\"  Best:  {best['fitness']:.2%} (Human prob) - Label: {best['label']}\")\n",
    "            print(f\"  Avg:   {avg_fit:.2%}\")\n",
    "            print(f\"  Worst: {worst_fit:.2%}\")\n",
    "            print(f\"\\nBest Individual (first 200 chars):\")\n",
    "            print(f\"  {best['text'][:200]}...\")\n",
    "        \n",
    "        # Check stopping criterion\n",
    "        if best['fitness'] >= target_fitness:\n",
    "            if verbose:\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"ðŸŽ¯ TARGET REACHED! Best fitness {best['fitness']:.2%} >= {target_fitness:.1%}\")\n",
    "                print(f\"{'='*80}\")\n",
    "            break\n",
    "        \n",
    "        # Selection\n",
    "        parents = select_top_k(evaluated, k=selection_size)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nSelected {len(parents)} parents for reproduction\")\n",
    "        \n",
    "        # Mutation\n",
    "        if gen < additional_generations - 1:\n",
    "            if verbose:\n",
    "                print(f\"Generating {population_size - len(parents)} mutated offspring...\")\n",
    "            population = mutate_population(parents, target_size=population_size)\n",
    "    \n",
    "    # Restore original generate_text\n",
    "    generate_text = original_generate_text\n",
    "    \n",
    "    # Final results\n",
    "    final_evaluated = evaluate_population(population)\n",
    "    best_final = final_evaluated[0]\n",
    "    \n",
    "    return {\n",
    "        'history': history,\n",
    "        'best_individual': best_final,\n",
    "        'final_population': final_evaluated,\n",
    "        'generations_run': len(history['generation'])\n",
    "    }\n",
    "\n",
    "\n",
    "# Resume from previous results (run this cell after rate limit recovers or to use mock fallback)\n",
    "print(\"Ready to resume GA evolution!\")\n",
    "print(\"Run the next cell to continue from the last checkpoint...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume the GA for 6 more generations (to reach generation 10)\n",
    "# This uses mock generation as fallback when API rate limits are hit\n",
    "\n",
    "ga_results = resume_genetic_algorithm(\n",
    "    previous_results=ga_results,\n",
    "    additional_generations=6,  # Complete remaining generations\n",
    "    population_size=10,\n",
    "    selection_size=3,\n",
    "    target_fitness=0.90,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ GA Evolution Completed!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a8e18",
   "metadata": {},
   "source": [
    "**Note:** The resume function automatically falls back to mock generation if the Gemini API rate limit is still active. This ensures the GA can complete all generations even with API restrictions.\n",
    "\n",
    "**Alternative:** If you want to wait for the API quota to refresh (typically 24 hours), run the resume cell later. The mock generation will still produce reasonable variations for demonstration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea310f",
   "metadata": {},
   "source": [
    "### 6.3 Visualize Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6ed84",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot fitness evolution\n",
    "history = ga_results['history']\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "Path('../output').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot 1: Fitness over generations\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['generation'], history['best_fitness'], 'o-', \n",
    "         color='green', linewidth=2, markersize=8, label='Best')\n",
    "plt.plot(history['generation'], history['avg_fitness'], 's--', \n",
    "         color='blue', linewidth=1.5, markersize=6, label='Average')\n",
    "plt.plot(history['generation'], history['worst_fitness'], '^:', \n",
    "         color='red', linewidth=1, markersize=6, label='Worst')\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Threshold (50%)')\n",
    "plt.axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, label='Target (90%)')\n",
    "plt.xlabel('Generation', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Human Probability (Fitness)', fontsize=12, fontweight='bold')\n",
    "plt.title('GA Evolution: Fitness Over Time', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot 2: Classification flip rate\n",
    "plt.subplot(1, 2, 2)\n",
    "flip_points = [1 if f >= 0.5 else 0 for f in history['best_fitness']]\n",
    "colors = ['red' if f < 0.5 else 'green' for f in history['best_fitness']]\n",
    "plt.bar(history['generation'], history['best_fitness'], color=colors, alpha=0.7)\n",
    "plt.axhline(y=0.5, color='black', linestyle='-', linewidth=2, label='Decision Boundary')\n",
    "plt.xlabel('Generation', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Best Human Probability', fontsize=12, fontweight='bold')\n",
    "plt.title('Detector Fooling Progress\\n(Red=AI, Green=Human)', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../output/ga_evolution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Plots saved to ../output/ga_evolution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad3256",
   "metadata": {},
   "source": [
    "### 6.4 Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9045ee9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best = ga_results['best_individual']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL RESULTS: SUPER-IMPOSTER\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nGenerations run: {ga_results['generations_run']}\")\n",
    "print(f\"\\nBest Individual Scores:\")\n",
    "print(f\"  Human probability: {best['human_prob']:.2%}\")\n",
    "print(f\"  AI probability:    {best['ai_prob']:.2%}\")\n",
    "print(f\"  Classification:    {best['label']}\")\n",
    "\n",
    "print(f\"\\nEvolution Summary:\")\n",
    "print(f\"  Initial best fitness:  {history['best_fitness'][0]:.2%}\")\n",
    "print(f\"  Final best fitness:    {history['best_fitness'][-1]:.2%}\")\n",
    "print(f\"  Improvement:           {(history['best_fitness'][-1] - history['best_fitness'][0]):.2%}\")\n",
    "\n",
    "if best['label'] == 'Human':\n",
    "    print(f\"\\nðŸŽ‰ SUCCESS! The detector was fooled!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Detector not fully fooled, but Human probability increased\")\n",
    "\n",
    "print(f\"\\n{'â”€'*80}\")\n",
    "print(\"SUPER-IMPOSTER TEXT:\")\n",
    "print(f\"{'â”€'*80}\")\n",
    "print(best['text'])\n",
    "print(f\"{'â”€'*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a870b42",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Part 2: The Personal Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cef9d1",
   "metadata": {},
   "source": [
    "### 7.1 Test User-Provided Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f0e10",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Example user text - replace with your own!\n",
    "user_text = \"\"\"\n",
    "I am deeply passionate about artificial intelligence and its potential to revolutionize healthcare. \n",
    "Throughout my academic journey, I have consistently sought opportunities to bridge theoretical knowledge \n",
    "with practical applications. Furthermore, my research experience in machine learning has equipped me \n",
    "with the necessary skills to contribute meaningfully to cutting-edge projects. Consequently, I believe \n",
    "that pursuing graduate studies at your institution would enable me to achieve my long-term career goals.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PERSONAL TEST: Analyzing Your Text\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nText (first 200 chars):\\n{user_text[:200]}...\\n\")\n",
    "\n",
    "# Detect\n",
    "result = detect_text(user_text)\n",
    "\n",
    "print(f\"Detection Results:\")\n",
    "print(f\"  Human probability: {result['human_prob']:.2%}\")\n",
    "print(f\"  AI probability:    {result['ai_prob']:.2%}\")\n",
    "print(f\"  Classification:    {result['label']}\")\n",
    "\n",
    "# Store for later use\n",
    "original_classification = result['label']\n",
    "original_human_prob = result['human_prob']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44cadc6",
   "metadata": {},
   "source": [
    "### 7.2 Provide Suggestions Based on Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303333e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def analyze_ai_markers(text: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Analyze text for common AI markers.\n",
    "    \"\"\"\n",
    "    ai_markers = [\n",
    "        'furthermore', 'moreover', 'consequently', 'thus', 'therefore',\n",
    "        'additionally', 'nevertheless', 'nonetheless', 'paradigm',\n",
    "        'framework', 'leverage', 'facilitate', 'optimize', 'comprehensive'\n",
    "    ]\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    found_markers = [marker for marker in ai_markers if marker in text_lower]\n",
    "    \n",
    "    # Check sentence structure\n",
    "    sentences = text.split('.')\n",
    "    avg_sent_len = np.mean([len(s.split()) for s in sentences if s.strip()])\n",
    "    \n",
    "    # Check for repetitive structure\n",
    "    sentence_starts = [s.strip().split()[0] if s.strip() else '' for s in sentences]\n",
    "    \n",
    "    return {\n",
    "        'ai_markers': found_markers,\n",
    "        'marker_count': len(found_markers),\n",
    "        'avg_sentence_length': avg_sent_len,\n",
    "        'sentence_count': len([s for s in sentences if s.strip()])\n",
    "    }\n",
    "\n",
    "print(f\"\\n{'â”€'*80}\")\n",
    "if original_classification == 'AI':\n",
    "    print(\"âš ï¸  TEXT CLASSIFIED AS AI-GENERATED\")\n",
    "    print(f\"{'â”€'*80}\")\n",
    "    \n",
    "    analysis = analyze_ai_markers(user_text)\n",
    "    \n",
    "    print(\"\\nDiagnostic Analysis:\")\n",
    "    print(f\"  AI marker words found: {analysis['marker_count']}\")\n",
    "    if analysis['ai_markers']:\n",
    "        print(f\"  Markers: {', '.join(analysis['ai_markers'])}\")\n",
    "    print(f\"  Average sentence length: {analysis['avg_sentence_length']:.1f} words\")\n",
    "    print(f\"  Total sentences: {analysis['sentence_count']}\")\n",
    "    \n",
    "    print(\"\\nðŸ’¡ Suggestions to Reduce AI Score:\")\n",
    "    print(\"  1. Remove formal connectives (furthermore, consequently, etc.)\")\n",
    "    print(\"  2. Vary sentence structure and length\")\n",
    "    print(\"  3. Use more concrete, specific examples\")\n",
    "    print(\"  4. Add personal anecdotes or informal language\")\n",
    "    print(\"  5. Introduce minor grammatical variations\")\n",
    "    \n",
    "else:\n",
    "    print(\"âœ“ TEXT CLASSIFIED AS HUMAN-WRITTEN\")\n",
    "    print(f\"{'â”€'*80}\")\n",
    "    print(\"\\nðŸ’¡ To make it sound MORE like AI (for testing):\")\n",
    "    print(\"  1. Add formal connectives (furthermore, moreover, consequently)\")\n",
    "    print(\"  2. Make sentences more uniform in structure\")\n",
    "    print(\"  3. Use more abstract, technical vocabulary\")\n",
    "    print(\"  4. Remove contractions and informal language\")\n",
    "    print(\"  5. Add logical transitions between ideas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f243a37",
   "metadata": {},
   "source": [
    "### 7.3 Manual Rewrite Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c59b8",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Rewrite the text based on classification\n",
    "if original_classification == 'AI':\n",
    "    # Rewrite to sound more human\n",
    "    rewritten_text = \"\"\"\n",
    "I've always been fascinated by AI and how it could transform healthcare. During my studies, \n",
    "I tried to connect what I learned in class with real-world problems. My research in machine learning \n",
    "taught me a lot - not just technical skills, but how to think creatively about solutions. \n",
    "I'm really excited about the possibility of joining your program because I think it's the perfect \n",
    "next step toward what I want to do with my career.\n",
    "\"\"\".strip()\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"REWRITE ATTEMPT: Making Text Sound More Human\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "else:\n",
    "    # Rewrite to sound more AI-like\n",
    "    rewritten_text = \"\"\"\n",
    "I am profoundly interested in artificial intelligence and its transformative potential within \n",
    "the healthcare sector. Furthermore, throughout my academic trajectory, I have consistently pursued \n",
    "opportunities to synthesize theoretical frameworks with practical implementations. Moreover, my \n",
    "extensive research experience in machine learning methodologies has equipped me with comprehensive \n",
    "competencies. Consequently, I am convinced that graduate studies at your esteemed institution \n",
    "would facilitate the achievement of my long-term professional objectives.\n",
    "\"\"\".strip()\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"REWRITE ATTEMPT: Making Text Sound More AI-Like\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nRewritten text:\\n{rewritten_text}\\n\")\n",
    "\n",
    "# Re-evaluate\n",
    "rewrite_result = detect_text(rewritten_text)\n",
    "\n",
    "print(f\"New Detection Results:\")\n",
    "print(f\"  Human probability: {rewrite_result['human_prob']:.2%}\")\n",
    "print(f\"  AI probability:    {rewrite_result['ai_prob']:.2%}\")\n",
    "print(f\"  Classification:    {rewrite_result['label']}\")\n",
    "\n",
    "# Compare\n",
    "print(f\"\\n{'â”€'*80}\")\n",
    "print(\"COMPARISON\")\n",
    "print(f\"{'â”€'*80}\")\n",
    "print(f\"Original:  {original_classification} ({original_human_prob:.2%} Human)\")\n",
    "print(f\"Rewritten: {rewrite_result['label']} ({rewrite_result['human_prob']:.2%} Human)\")\n",
    "\n",
    "if original_classification == 'AI':\n",
    "    if rewrite_result['label'] == 'Human':\n",
    "        print(f\"\\nâœ… SUCCESS! Fooled the detector!\")\n",
    "    elif rewrite_result['human_prob'] > original_human_prob:\n",
    "        print(f\"\\nðŸ“ˆ IMPROVEMENT! Human probability increased by {(rewrite_result['human_prob'] - original_human_prob):.2%}\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  No improvement\")\n",
    "else:\n",
    "    if rewrite_result['label'] == 'AI':\n",
    "        print(f\"\\nâœ… SUCCESS! Made it sound like AI!\")\n",
    "    elif rewrite_result['ai_prob'] > result['ai_prob']:\n",
    "        print(f\"\\nðŸ“ˆ IMPROVEMENT! AI probability increased by {(rewrite_result['ai_prob'] - result['ai_prob']):.2%}\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  No significant change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d1919",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d222fe",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TASK 4 SUMMARY: THE TURING TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š PART 1: SUPER-IMPOSTER (GA ATTACK)\")\n",
    "print(\"â”€\"*80)\n",
    "print(f\"  Initial population fitness: {history['best_fitness'][0]:.2%}\")\n",
    "print(f\"  Final best fitness:         {history['best_fitness'][-1]:.2%}\")\n",
    "print(f\"  Generations to converge:    {ga_results['generations_run']}\")\n",
    "print(f\"  Detector fooled:            {'YES' if best['label'] == 'Human' else 'NO'}\")\n",
    "print(f\"  Fitness improvement:        {(history['best_fitness'][-1] - history['best_fitness'][0]):.2%}\")\n",
    "\n",
    "print(\"\\nðŸ‘¤ PART 2: PERSONAL TEST\")\n",
    "print(\"â”€\"*80)\n",
    "print(f\"  Original classification:    {original_classification}\")\n",
    "print(f\"  Original Human prob:        {original_human_prob:.2%}\")\n",
    "print(f\"  Rewritten classification:   {rewrite_result['label']}\")\n",
    "print(f\"  Rewritten Human prob:       {rewrite_result['human_prob']:.2%}\")\n",
    "print(f\"  Successfully modified:      {'YES' if rewrite_result['label'] != original_classification else 'NO'}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ KEY INSIGHTS\")\n",
    "print(\"â”€\"*80)\n",
    "print(\"  1. GA successfully evolves text toward higher Human probability\")\n",
    "print(\"  2. LLM-as-Mutator is effective for adversarial text generation\")\n",
    "print(\"  3. Removing AI-isms (furthermore, consequently) helps evasion\")\n",
    "print(\"  4. Varying sentence structure reduces detection confidence\")\n",
    "print(\"  5. Manual rewrites can flip classification with targeted edits\")\n",
    "\n",
    "print(\"\\nâš ï¸  LIMITATIONS\")\n",
    "print(\"â”€\"*80)\n",
    "print(\"  â€¢ GA uses mock LLM generation (for demo purposes)\")\n",
    "print(\"  â€¢ Real Gemini API would provide better mutations\")\n",
    "print(\"  â€¢ Detector may be overfitted to specific AI patterns\")\n",
    "print(\"  â€¢ Adversarial examples may not generalize to other detectors\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ Task 4 Complete\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9431569,
     "sourceId": 14756256,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
